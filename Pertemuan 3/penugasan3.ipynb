{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "16b41695",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "from spacy.lang.id import Indonesian\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae9c0bc",
   "metadata": {},
   "source": [
    "### TOKENISASI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d503af0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/asus/bahan python/berita\"\n",
    "\n",
    "\n",
    "import spacy\n",
    "nlp_task = Indonesian()\n",
    "corpus = []\n",
    "corpus_term = []\n",
    "for file in os.listdir(path): \n",
    "    with open(os.path.join(path, file), 'r') as f:\n",
    "        clean_txt = re.sub(\"http\\S+\", '', f.read()) #menggantikan bentuk link (\"https\") menjadi \"\"\n",
    "        clean_txt = re.sub(\"[\\n\\n]\", ' ', clean_txt) #menggantikan double new line dengan ' '\n",
    "        corpus.append(clean_txt) #menambahkan fungsi clean_text (yang telah dilakukan perlakuan) ke corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "45cbd9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Wilayah', 'Kamu', 'Sudah', \"'\", 'Bebas', \"'\", 'COVID', '-', '19', '?', 'Cek', '34', 'Kab', '/', 'Kota', 'Zona', 'Hijau', 'Terbaru', ' ', 'Jakarta', '-', 'Pemerintah', 'rencananya', 'bakal', 'menerapkan', 'Pemberlakuan', 'Pembatasan', 'Kegiatan', 'Masyarakat', '(', 'PPKM', ')', 'level', '3', 'terhitung', '24', 'Desember', '2021', 'hingga', '2', 'Januari', '2021', '.', 'Namun', ',', 'Kementerian', 'Kesehatan', 'RI', 'memastikan', 'kebijakan', 'PPKM', 'level', '3', 'ini', 'masih', 'dalam', 'tahap', 'kajian', '.', 'Menurut', 'Direktur', 'Pencegahan', 'dan', 'Pengendalian', 'Penyakit', 'Menular', 'Langsung', '(', 'P2PML', ')', 'Kemenkes', 'RI', 'dr', 'Siti', 'Nadia', 'Tarmizi', ',', 'PPKM', 'level', '3', 'bakal', 'diterapkan', 'jika', 'kasus', 'COVID', '-', '19', 'naik', 'signifikan', '.', 'Hal', 'ini', 'umumnya', 'dipicu', 'dengan', 'peningkatan', 'mobilitas', 'dan', 'pelonggaran', 'protokol', 'kesehatan', '.', ' '], ['Vaksin', 'COVID', '-', '19', 'Bakal', 'Rutin', 'Setiap', 'Tahun', '?', 'Tergantung', ',', 'Ini', 'Penjelasannya', ' ', 'Jakarta', '-', 'Pemberian', 'booster', 'atau', 'dosis', 'ketiga', 'vaksin', 'COVID', '-', '19', 'di', 'Indonesia', 'direncanakan', 'bakal', 'berlangsung', 'Januari', '2022', '.', 'Lantas', 'adakah', 'kemungkinan', 'vaksinasi', 'COVID', '-', '19', 'bakal', 'harus', 'dilakukan', 'setiap', 'tahun', 'seperti', 'vaksinasi', 'influenza', '?', 'Ketua', 'Satgas', 'COVID', '-', '19', 'Ikatan', 'Dokter', 'Indonesia', '(', 'IDI', ')', 'Prof', 'Zubairi', 'Djoerban', 'menjelaskan', 'hingga', 'kini', 'belum', 'ada', 'kepastian', 'terkait', 'hal', 'tersebut', '.', 'Menurutnya', 'masih', 'ada', 'kemungkinan', 'vaksin', 'COVID', '-', '19', 'harus', 'diberikan', 'setiap', 'tahun', ',', 'ada', 'juga', 'kemungkinan', 'cukup', 'booster', 'diberikan', 'sekali', 'kemudian', 'vaksinasi', 'COVID', '-', '19', 'tidak', 'diperlukan', 'lagi', '.', ' '], ['RI', 'Mulai', 'Suntikkan', 'Booster', 'di', '2022', ',', 'Masihkah', 'Ampuh', 'Lawan', 'Varian', 'Delta', 'Cs', '?', ' ', 'Jakarta', '-', 'Pakar', 'mengakui', 'vaksin', '-', 'vaksin', 'yang', 'sudah', 'digunakan', 'untuk', 'dosis', '1', '-', '2', 'memang', 'mengalami', 'penurunan', 'efektivitas', 'terhadap', 'varian', 'baru', 'Corona', 'seperti', 'varian', 'Delta', '.', 'Mengingat', 'booster', 'atau', 'dosis', 'ketiga', 'vaksin', 'COVID', '-', '19', 'di', 'Indonesia', 'disebut', 'bakal', 'dimulai', 'awal', '2022', ',', 'apakah', 'jenis', 'vaksin', 'yang', 'digunakan', 'bakal', 'mengikuti', 'strain', 'virus', 'terbaru', '?', 'Menjawab', 'pertanyaan', 'tersebut', ',', 'Ketua', 'Satgas', 'COVID', '-', '19', 'Ikatan', 'Dokter', 'Indonesia', '(', 'IDI', ')', 'Prof', 'Zubairi', 'Djoerban', 'kembali', 'menyinggung', 'riset', 'yang', 'sudah', 'berlangsung', 'terkait', 'efektivitas', 'vaksin', 'COVID', '-', '19', 'dosis', '1', 'dan', '2', '.', 'Ia', 'menyebut', 'berdasarkan', 'riset', 'sejauh', 'ini', ',', 'efektivitas', 'vaksin', 'COVID', '-', '19', 'Pfizer', 'dan', 'Moderna', 'terbukti', 'menurun', 'dalam', 'melawan', 'varian', 'Delta', '.', ' '], ['Alert', '!', 'Kasus', 'Varian', 'Delta', 'COVID', '-', '19', 'di', 'DKI', 'Meningkat', ' ', 'Jakarta', '-', 'Data', 'terbaru', 'dari', 'Balitbangkes', 'Kemenkes', 'RI', 'per', '13', 'November', ',', 'menunjukkan', 'adanya', 'penambahan', 'varian', 'Delta', '.', 'Penambahan', 'tersebut', 'terjadi', 'di', 'Jawa', 'Barat', 'ada', '165', 'kasus', ',', 'DKI', 'Jakarta', '90', 'kasus', ',', 'dan', 'Sulawesi', 'Utara', '86', 'kasus', '.', 'Dalam', 'satu', 'bulan', 'terakhir', ',', 'Balitbangkes', 'menyebutkan', 'DKI', 'Jakarta', 'mengalami', 'peningkatan', 'kasus', 'varian', 'Delta', 'yang', 'signifikan', '.', 'Sementara', ',', 'pada', 'varian', 'baru', 'seperti', 'varian', 'Alpha', ',', 'varian', 'Delta', ',', 'hingga', 'Beta', 'terbanyak', 'di', 'Indonesia', 'berasal', 'dari', 'DKI', 'Jakarta', ',', 'dengan', 'total', '1.327', 'kasus', '.', ' '], ['Corona', 'di', 'AS', 'Mendadak', 'Naik', 'Lagi', 'Usai', 'Serangan', 'Delta', 'Sempat', 'Mereda', ' ', 'Jakarta', '-', 'Kasus', 'COVID', '-', '19', 'kembali', 'naik', 'di', 'sejumlah', 'wilayah', 'Amerika', 'Serikat', '(', 'AS', ')', '.', 'Padahal', 'diketahui', ',', 'COVID', '-', '19', 'sempat', 'tercatat', 'stabil', 'pasca', 'serangan', 'varian', 'Delta', 'musim', 'panas', 'ini', '.', 'Ada', 'apa', '?', 'Hal', 'tersebut', 'disampaikan', 'oleh', 'kepala', 'penasihat', 'medis', 'Gedung', 'Putih', 'Dr.', 'Anthony', 'Fauci', ',', 'Senin', '(', '15', '/', '11', '/', '2021', ')', '.', 'Diketahui', ',', 'kasus', 'nasional', 'turun', '57', 'persen', 'minggu', 'lalu', 'dari', 'puncak', 'gelombang', 'varian', 'Delta', 'pada', 'musim', 'panas', '.', 'Namun', 'jumlah', 'pasien', 'COVID', '-', '19', 'di', 'area', 'Barat', 'Tengah', 'dan', 'Timur', 'laut', 'kini', 'naik', 'mendadak', '.', ' ']]\n"
     ]
    }
   ],
   "source": [
    "# 1. Tokenization\n",
    "#melakukan replacement text menjadi sepenggal-sepenggal (string dan char)\n",
    "for doc in corpus:\n",
    "    token_kata = [token.text for token in nlp_task(doc)]\n",
    "    corpus_term.append(token_kata) #menambahkan fungsi token_kata ke dalam corpus_term\n",
    "    \n",
    "print(corpus_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "924d7667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Wilayah', 'Kamu', 'Sudah', \"'\", 'Bebas', \"'\", 'COVID', '-', '19', '?', 'Cek', '34', 'Kab', '/', 'Kota', 'Zona', 'Hijau', 'Terbaru', ' ', 'Jakarta', '-', 'Pemerintah', 'rencananya', 'menerapkan', 'Pemberlakuan', 'Pembatasan', 'Kegiatan', 'Masyarakat', '(', 'PPKM', ')', 'level', '3', 'terhitung', '24', 'Desember', '2021', '2', 'Januari', '2021', '.', 'Namun', ',', 'Kementerian', 'Kesehatan', 'RI', 'kebijakan', 'PPKM', 'level', '3', 'tahap', 'kajian', '.', 'Menurut', 'Direktur', 'Pencegahan', 'Pengendalian', 'Penyakit', 'Menular', 'Langsung', '(', 'P2PML', ')', 'Kemenkes', 'RI', 'dr', 'Siti', 'Nadia', 'Tarmizi', ',', 'PPKM', 'level', '3', 'diterapkan', 'COVID', '-', '19', 'signifikan', '.', 'Hal', 'dipicu', 'peningkatan', 'mobilitas', 'pelonggaran', 'protokol', 'kesehatan', '.', ' '], ['Vaksin', 'COVID', '-', '19', 'Bakal', 'Rutin', 'Setiap', 'Tahun', '?', 'Tergantung', ',', 'Ini', 'Penjelasannya', ' ', 'Jakarta', '-', 'Pemberian', 'booster', 'dosis', 'ketiga', 'vaksin', 'COVID', '-', '19', 'Indonesia', 'direncanakan', 'Januari', '2022', '.', 'Lantas', 'adakah', 'vaksinasi', 'COVID', '-', '19', 'vaksinasi', 'influenza', '?', 'Ketua', 'Satgas', 'COVID', '-', '19', 'Ikatan', 'Dokter', 'Indonesia', '(', 'IDI', ')', 'Prof', 'Zubairi', 'Djoerban', 'kepastian', 'terkait', '.', 'Menurutnya', 'vaksin', 'COVID', '-', '19', ',', 'booster', 'vaksinasi', 'COVID', '-', '19', '.', ' '], ['RI', 'Mulai', 'Suntikkan', 'Booster', '2022', ',', 'Masihkah', 'Ampuh', 'Lawan', 'Varian', 'Delta', 'Cs', '?', ' ', 'Jakarta', '-', 'Pakar', 'mengakui', 'vaksin', '-', 'vaksin', 'dosis', '1', '-', '2', 'mengalami', 'penurunan', 'efektivitas', 'varian', 'Corona', 'varian', 'Delta', '.', 'Mengingat', 'booster', 'dosis', 'ketiga', 'vaksin', 'COVID', '-', '19', 'Indonesia', '2022', ',', 'jenis', 'vaksin', 'mengikuti', 'strain', 'virus', 'terbaru', '?', 'Menjawab', ',', 'Ketua', 'Satgas', 'COVID', '-', '19', 'Ikatan', 'Dokter', 'Indonesia', '(', 'IDI', ')', 'Prof', 'Zubairi', 'Djoerban', 'menyinggung', 'riset', 'terkait', 'efektivitas', 'vaksin', 'COVID', '-', '19', 'dosis', '1', '2', '.', 'Ia', 'menyebut', 'berdasarkan', 'riset', ',', 'efektivitas', 'vaksin', 'COVID', '-', '19', 'Pfizer', 'Moderna', 'terbukti', 'menurun', 'melawan', 'varian', 'Delta', '.', ' '], ['Alert', '!', 'Kasus', 'Varian', 'Delta', 'COVID', '-', '19', 'DKI', 'Meningkat', ' ', 'Jakarta', '-', 'Data', 'terbaru', 'Balitbangkes', 'Kemenkes', 'RI', '13', 'November', ',', 'penambahan', 'varian', 'Delta', '.', 'Penambahan', 'Jawa', 'Barat', '165', ',', 'DKI', 'Jakarta', '90', ',', 'Sulawesi', 'Utara', '86', '.', 'Dalam', ',', 'Balitbangkes', 'DKI', 'Jakarta', 'mengalami', 'peningkatan', 'varian', 'Delta', 'signifikan', '.', 'Sementara', ',', 'varian', 'varian', 'Alpha', ',', 'varian', 'Delta', ',', 'Beta', 'Indonesia', 'berasal', 'DKI', 'Jakarta', ',', 'total', '1.327', '.', ' '], ['Corona', 'AS', 'Mendadak', 'Naik', 'Lagi', 'Usai', 'Serangan', 'Delta', 'Sempat', 'Mereda', ' ', 'Jakarta', '-', 'Kasus', 'COVID', '-', '19', 'wilayah', 'Amerika', 'Serikat', '(', 'AS', ')', '.', 'Padahal', ',', 'COVID', '-', '19', 'tercatat', 'stabil', 'pasca', 'serangan', 'varian', 'Delta', 'musim', 'panas', '.', 'Ada', '?', 'Hal', 'kepala', 'penasihat', 'medis', 'Gedung', 'Putih', 'Dr.', 'Anthony', 'Fauci', ',', 'Senin', '(', '15', '/', '11', '/', '2021', ')', '.', 'Diketahui', ',', 'nasional', 'turun', '57', 'persen', 'minggu', 'puncak', 'gelombang', 'varian', 'Delta', 'musim', 'panas', '.', 'Namun', 'pasien', 'COVID', '-', '19', 'area', 'Barat', 'Tengah', 'Timur', 'laut', 'mendadak', '.', ' ']]\n"
     ]
    }
   ],
   "source": [
    "#STOPWORDS ELIMINATION\n",
    "\n",
    "nlp_task = Indonesian()\n",
    "stop_words = nlp_task.Defaults.stop_words\n",
    "corpus_term_stopwords = []\n",
    "\n",
    "for doc in corpus:\n",
    "    nlp_doc = nlp_task(doc)\n",
    "    token_kata = [token.text for token in nlp_doc]\n",
    "    token_stopwords = [w for w in token_kata if w not in stop_words] #melakukan pengecualian terhadap stop words\n",
    "    corpus_term_stopwords.append(token_stopwords)\n",
    "\n",
    "print(corpus_term_stopwords)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ca1fd48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEMMING\n",
    "stemmer_tugas = StemmerFactory().create_stemmer()\n",
    "corpus_stem = []\n",
    "corps = []\n",
    "\n",
    "for doc in corpus:\n",
    "    for j in doc:\n",
    "        corpus_stem.append(stemmer_tugas.stem(j))\n",
    "    corps.append(doc.lower())\n",
    "    corpus_term =[]\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "871c93b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fungsi untuk stemming\n",
    "\n",
    "def stemming (corpus):\n",
    "    #import StemmerFactory class\n",
    "    from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "    #create stemmer\n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    "    \n",
    "    # stemming process\n",
    "    output   = stemmer.stem(corpus)\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "24f00747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wilayah': [1, 5], 'kamu': [1], 'sudah': [1, 3], '': [1, 2, 3, 4, 5], 'bebas': [1], 'covid': [1, 2, 3, 4, 5], '-': [1, 2, 3, 4, 5], '19': [1, 2, 3, 4, 5], 'cek': [1], '34': [1], 'kab': [1], 'kota': [1], 'zona': [1], 'hijau': [1], 'baru': [1, 3, 4], 'jakarta': [1, 2, 3, 4, 5], 'perintah': [1], 'rencana': [1, 2], 'bakal': [1, 2, 3], 'terap': [1], 'laku': [1, 2], 'batas': [1], 'giat': [1], 'masyarakat': [1], 'ppkm': [1], 'level': [1], '3': [1], 'hitung': [1], '24': [1], 'desember': [1], '2021': [1, 5], 'hingga': [1, 2, 4], '2': [1, 3], 'januari': [1, 2], 'namun': [1, 5], 'menteri': [1], 'sehat': [1], 'ri': [1, 3, 4], 'pasti': [1, 2], 'bijak': [1], 'ini': [1, 2, 3, 5], 'masih': [1, 2, 3], 'dalam': [1, 3, 4], 'tahap': [1], 'kaji': [1], 'turut': [1, 2], 'direktur': [1], 'cegah': [1], 'dan': [1, 3, 4, 5], 'kendali': [1], 'sakit': [1], 'tular': [1], 'langsung': [1, 2, 3], 'p2pml': [1], 'kemenkes': [1, 4], 'dr': [1, 5], 'siti': [1], 'nadia': [1], 'tarmizi': [1], 'jika': [1], 'kasus': [1, 4, 5], 'naik': [1, 5], 'signifikan': [1, 4], 'hal': [1, 2, 5], 'umum': [1], 'picu': [1], 'dengan': [1, 4], 'tingkat': [1, 4], 'mobilitas': [1], 'longgar': [1], 'protokol': [1], 'vaksin': [2, 3], 'rutin': [2], 'tiap': [2], 'tahun': [2], 'gantung': [2], 'jelas': [2], 'beri': [2], 'booster': [2, 3], 'atau': [2, 3], 'dosis': [2, 3], 'tiga': [2, 3], 'di': [2, 3, 4, 5], 'indonesia': [2, 3, 4], '2022': [2, 3], 'lantas': [2], 'ada': [2, 4, 5], 'mungkin': [2], 'vaksinasi': [2], 'harus': [2], 'seperti': [2, 3, 4], 'influenza': [2], 'ketua': [2, 3], 'satgas': [2, 3], 'ikat': [2, 3], 'dokter': [2, 3], 'idi': [2, 3], 'prof': [2, 3], 'zubairi': [2, 3], 'djoerban': [2, 3], 'kini': [2, 5], 'belum': [2], 'kait': [2, 3], 'sebut': [2, 3, 4, 5], 'juga': [2], 'cukup': [2], 'sekali': [2], 'kemudian': [2], 'tidak': [2], 'perlu': [2], 'lagi': [2, 5], 'mulai': [3], 'suntik': [3], 'ampuh': [3], 'lawan': [3], 'varian': [3, 4, 5], 'delta': [3, 4, 5], 'cs': [3], 'pakar': [3], 'aku': [3], 'yang': [3, 4], 'guna': [3], 'untuk': [3], '1': [3], 'memang': [3], 'alami': [3, 4], 'turun': [3, 5], 'efektivitas': [3], 'hadap': [3], 'corona': [3, 5], 'ingat': [3], 'awal': [3], 'apakah': [3], 'jenis': [3], 'ikut': [3], 'strain': [3], 'virus': [3], 'jawab': [3], 'tanya': [3], 'kembali': [3, 5], 'singgung': [3], 'riset': [3], 'ia': [3], 'dasar': [3], 'jauh': [3], 'pfizer': [3], 'moderna': [3], 'bukti': [3], 'alert': [4], 'dki': [4], 'data': [4], 'dari': [4, 5], 'balitbangkes': [4], 'per': [4], '13': [4], 'november': [4], 'tunjuk': [4], 'tambah': [4], 'jadi': [4], 'jawa': [4], 'barat': [4, 5], '165': [4], '90': [4], 'sulawesi': [4], 'utara': [4], '86': [4], 'satu': [4], 'bulan': [4], 'akhir': [4], 'sementara': [4], 'pada': [4, 5], 'alpha': [4], 'beta': [4], 'banyak': [4], 'asal': [4], 'total': [4], '1 327': [4], 'as': [5], 'dadak': [5], 'usai': [5], 'serang': [5], 'sempat': [5], 'reda': [5], 'jumlah': [5], 'amerika': [5], 'serikat': [5], 'padahal': [5], 'tahu': [5], 'catat': [5], 'stabil': [5], 'pasca': [5], 'musim': [5], 'panas': [5], 'apa': [5], 'sampai': [5], 'oleh': [5], 'kepala': [5], 'nasihat': [5], 'medis': [5], 'gedung': [5], 'putih': [5], 'anthony': [5], 'fauci': [5], 'senin': [5], '15': [5], '11': [5], 'nasional': [5], '57': [5], 'persen': [5], 'minggu': [5], 'lalu': [5], 'puncak': [5], 'gelombang': [5], 'pasien': [5], 'area': [5], 'tengah': [5], 'timur': [5], 'laut': [5]}\n"
     ]
    }
   ],
   "source": [
    "#INVERTED INDEX\n",
    "# mendapatkan inverted index pada corpus di atas dengan menambahkan fungsi stemming agar menjadi kata dasar\n",
    "inverted_index = {}\n",
    " \n",
    "for i in range(len(corpus_term)):\n",
    "    for item in corpus_term[i]: \n",
    "        item = stemming(item) #funsgi stemming\n",
    "        if item not in inverted_index:\n",
    "            inverted_index[item] = []\n",
    "        if (item in inverted_index) and ((i+1) not in inverted_index[item]):\n",
    "            inverted_index[item].append(i+1)\n",
    "print(inverted_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b9dfca55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class BooleanModel():\n",
    "    \n",
    "    @staticmethod\n",
    "    def and_operation(left_operand, right_operand):\n",
    "        # perform 'merge'\n",
    "        result = [] # results list to be returned\n",
    "        l_index = 0 # current index in left_operand\n",
    "        r_index = 0 # current index in right_operand\n",
    "        \n",
    "        l_skip = int(math.sqrt(len(left_operand)))\n",
    "        # skip pointer distance for l_index\n",
    "        \n",
    "        r_skip = int(math.sqrt(len(right_operand)))\n",
    "        # skip pointer distance for r_index\n",
    "        while (l_index < len(left_operand) and r_index < len(right_operand)):\n",
    "            l_item = left_operand[l_index]\n",
    "            r_item = right_operand[r_index]\n",
    "            # case 1: if match\n",
    "            if (l_item == r_item):\n",
    "                result.append(l_item) # add to results\n",
    "                l_index += 1 # advance left index\n",
    "                r_index += 1 # advance right index\n",
    "                \n",
    "                # case 2: if left item is more than right item\n",
    "            elif (l_item > r_item):\n",
    "                # if r_index can be skipped (if new r_index is still within range and resulting item is <= left item)\n",
    "                if (r_index + r_skip < len(right_operand)) and right_operand[r_index + r_skip] <= l_item:\n",
    "                    r_index += r_skip\n",
    "                    # else advance r_index by 1\n",
    "                else:\n",
    "                    r_index += 1    \n",
    "            # case 3: if left item is less than right item\n",
    "            else:\n",
    "                # if l_index can be skipped (if new l_index is still within range and resulting item is <= right item)\n",
    "                if (l_index + l_skip < len(left_operand)) and left_operand[l_index + l_skip] <= r_item:\n",
    "                    l_index += l_skip\n",
    "                    # else advance l_index by 1\n",
    "                else:\n",
    "                    l_index += 1\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def or_operation(left_operand, right_operand):\n",
    "        result = [] # union of left and right operand\n",
    "        l_index = 0 # current index in left_operand\n",
    "        r_index = 0 # current index in right_operand\n",
    "        # while lists have not yet been covered\n",
    "        while (l_index < len(left_operand) or r_index < len(right_operand)):\n",
    "            # if both list are not yet exhausted\n",
    "            if (l_index < len(left_operand) and r_index < len(right_operand)):\n",
    "                l_item = left_operand[l_index] # current item in left_operand\n",
    "                r_item = right_operand[r_index] # current item in right_operand\n",
    "                \n",
    "                # case 1: if items are equal, add either one to result and advance both pointers\n",
    "                if (l_item == r_item):\n",
    "                    result.append(l_item)\n",
    "                    l_index += 1\n",
    "                    r_index += 1\n",
    "\n",
    "                # case 2: l_item greater than r_item, add r_item and advance r_index\n",
    "                elif (l_item > r_item):\n",
    "                        result.append(r_item)\n",
    "                        r_index += 1\n",
    "                # case 3: l_item lower than r_item, add l_item and advance l_index\n",
    "                else:\n",
    "                    result.append(l_item)\n",
    "                    l_index += 1\n",
    "                    \n",
    "            # if left_operand list is exhausted, append r_item and advance r_index\n",
    "            elif (l_index >= len(left_operand)):\n",
    "                r_item = right_operand[r_index]\n",
    "                result.append(r_item)\n",
    "                r_index += 1\n",
    "            # else if right_operand list is exhausted, append l_item and advance l_index\n",
    "            else:\n",
    "                l_item = left_operand[l_index]\n",
    "                result.append(l_item)\n",
    "                l_index += 1\n",
    "        return result\n",
    "  \n",
    "    @staticmethod\n",
    "    def not_operation(right_operand, indexed_docIDs):\n",
    "        # complement of an empty list is list of all indexed docIDs\n",
    "        if (not right_operand):\n",
    "            return indexed_docIDs\n",
    "            result = []\n",
    "            r_index = 0 # index for right operand\n",
    "            for item in indexed_docIDs:\n",
    "                # if item do not match that in right_operand, it belongs to compliment\n",
    "                if (item != right_operand[r_index]):\n",
    "                    result.append(item)\n",
    "                # else if item matches and r_index still can progress, advance it by 1\n",
    "                elif (r_index + 1 < len(right_operand)):\n",
    "                    r_index += 1\n",
    "        return result\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9fa78d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fungsi parse query\n",
    "def parse_query(infix_tokens):\n",
    "    \"\"\" Parse Query\n",
    "    Parsing done using Shunting Yard Algorithm \n",
    "    \"\"\"\n",
    "    precedence = {}\n",
    "    precedence['NOT'] = 3\n",
    "    precedence['AND'] = 2\n",
    "    precedence['OR'] = 1\n",
    "    precedence['('] = 0\n",
    "    precedence[')'] = 0\n",
    "    \n",
    "    output = []\n",
    "    operator_stack = []\n",
    "    \n",
    "    for token in infix_tokens:\n",
    "        if (token == '('):\n",
    "            operator_stack.append(token)\n",
    "        # if right bracket, pop all operators from operator stack onto output until we hit left bracket\n",
    "        elif (token == ')'):\n",
    "            operator = operator_stack.pop()\n",
    "            while operator != '(':\n",
    "                output.append(operator)\n",
    "        # if operator, pop operators from operator stack to queue if they are of higher precedence\n",
    "        elif (token in precedence):\n",
    "            # if operator stack is not empty\n",
    "            if (operator_stack):\n",
    "                current_operator = operator_stack[-1]\n",
    "                while (operator_stack and precedence[current_operator] > precedence[token]):\n",
    "                    output.append(operator_stack.pop())\n",
    "                    if (operator_stack):\n",
    "                        current_operator = operator_stack[-1]\n",
    "            operator_stack.append(token) # add token to stack\n",
    "        else:\n",
    "            output.append(token.lower())\n",
    "    # while there are still operators on the stack, pop them into the queue\n",
    "    while (operator_stack):\n",
    "        output.append(operator_stack.pop())\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fb4936bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fungsi proses query untuk mengeksekusi query \n",
    "# terdapat beberapa parameter yang digunakan yaitu query itu sendri, \n",
    "# jumlah dokumen, dan inverted index yang telah dibuat sebelumnya\n",
    "\n",
    "import collections\n",
    "BooleanModel()\n",
    "\n",
    "def process_query(query, n_docs, inverted_index):\n",
    "    # prepare query list\n",
    "    query = query.replace('(', '( ')\n",
    "    query = query.replace(')', ' )')\n",
    "    query = query.split(' ')\n",
    "    print(query)\n",
    "    \n",
    "    indexed_docIDs = list(range(1, n_docs + 1))\n",
    "    results_stack = []\n",
    "    postfix_queue = collections.deque(parse_query(query)) # get query in postfix notation as a queue\n",
    "\n",
    "    while postfix_queue:\n",
    "        token = postfix_queue.popleft()\n",
    "        result = [] # the evaluated result at each stage\n",
    "        # if operand, add postings list for term to results stack\n",
    "        if (token != 'AND' and token != 'OR' and token != 'NOT'):\n",
    "            token = stemming(token) # stem the token\n",
    "            # default empty list if not in dictionary\n",
    "            if (token in inverted_index):\n",
    "                result = inverted_index[token]\n",
    "        elif (token == 'AND'):\n",
    "            right_operand = results_stack.pop()\n",
    "            left_operand = results_stack.pop()\n",
    "            result = BooleanModel.and_operation(left_operand, right_operand) # evaluate AND\n",
    "        elif (token == 'OR'):\n",
    "            right_operand = results_stack.pop()\n",
    "            left_operand = results_stack.pop()\n",
    "            result = BooleanModel.or_operation(left_operand, right_operand) # evaluate OR\n",
    "        elif (token == 'NOT'):\n",
    "            right_operand = results_stack.pop()\n",
    "            result = BooleanModel.not_operation(right_operand, indexed_docIDs) # evaluate NOT\n",
    "        results_stack.append(result) \n",
    "        \n",
    "    # NOTE: at this point results_stack should only have one item and it is the final result\n",
    "    if len(results_stack) != 1: \n",
    "        print(\"ERROR: Invalid Query. Please check query syntax.\") # check for errors\n",
    "        return None\n",
    "\n",
    "    return results_stack.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7cf5495d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['corona']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3, 5]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_query(\"corona\", len(corpus), inverted_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "64940a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['covid']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_query(\"covid\", len(corpus), inverted_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f538fa1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['corona', 'OR', 'covid']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_query(\"corona OR covid\", len(corpus), inverted_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a4e07706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['corona', 'AND', 'covid']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3, 5]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_query(\"corona AND covid\", len(corpus), inverted_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2920ffa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vaksin', 'AND', 'corona']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_query(\"vaksin AND corona\", len(corpus), inverted_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957a65c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
