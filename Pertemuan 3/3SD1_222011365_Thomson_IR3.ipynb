{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4d0a193",
   "metadata": {},
   "source": [
    "# TUGAS INFORMATION RETRIEVAL\n",
    "\n",
    "Nama : Thomson\n",
    "\n",
    "NIM  : 222011365\n",
    "\n",
    "Kelas: 3SD1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53424755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "from spacy.lang.id import Indonesian #mengimpor package nlp untuk bahasa\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory #mengimpor pacakge untuk stemming\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f750d6fe",
   "metadata": {},
   "source": [
    "# Inputing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af853323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wilayah kamu sudah bebas covid-19 cek 34 kab kota zona hijau terbaru jakarta - pemerintah rencananya bakal menerapkan pemberlakuan pembatasan kegiatan masyarakat ppkm level 3 terhitung 24 desember 2021 hingga 2 januari 2021. namun kementerian kesehatan ri memastikan kebijakan ppkm level 3 ini masih dalam tahap kajian. menurut direktur pencegahan dan pengendalian penyakit menular langsung p2pml kemenkes ri dr siti nadia tarmizi ppkm level 3 bakal diterapkan jika kasus covid-19 naik signifikan. hal ini umumnya dipicu dengan peningkatan mobilitas dan pelonggaran protokol kesehatan. ', 'vaksin covid-19 bakal rutin setiap tahun tergantung ini penjelasannya jakarta - pemberian booster atau dosis ketiga vaksin covid-19 di indonesia direncanakan bakal berlangsung januari 2022. lantas adakah kemungkinan vaksinasi covid-19 bakal harus dilakukan setiap tahun seperti vaksinasi influenza ketua satgas covid-19 ikatan dokter indonesia idi prof zubairi djoerban menjelaskan hingga kini belum ada kepastian terkait hal tersebut. menurutnya masih ada kemungkinan vaksin covid-19 harus diberikan setiap tahun ada juga kemungkinan cukup booster diberikan sekali kemudian vaksinasi covid-19 tidak diperlukan lagi. ', 'ri mulai suntikkan booster di 2022 masihkah ampuh lawan varian delta cs jakarta - pakar mengakui vaksin-vaksin yang sudah digunakan untuk dosis 1-2 memang mengalami penurunan efektivitas terhadap varian baru corona seperti varian delta. mengingat booster atau dosis ketiga vaksin covid-19 di indonesia disebut bakal dimulai awal 2022 apakah jenis vaksin yang digunakan bakal mengikuti strain virus terbaru menjawab pertanyaan tersebut ketua satgas covid-19 ikatan dokter indonesia idi prof zubairi djoerban kembali menyinggung riset yang sudah berlangsung terkait efektivitas vaksin covid-19 dosis 1 dan 2. ia menyebut berdasarkan riset sejauh ini efektivitas vaksin covid-19 pfizer dan moderna terbukti menurun dalam melawan varian delta. ', 'alert kasus varian delta covid-19 di dki meningkat jakarta - data terbaru dari balitbangkes kemenkes ri per 13 november menunjukkan adanya penambahan varian delta. penambahan tersebut terjadi di jawa barat ada 165 kasus dki jakarta 90 kasus dan sulawesi utara 86 kasus. dalam satu bulan terakhir balitbangkes menyebutkan dki jakarta mengalami peningkatan kasus varian delta yang signifikan. sementara pada varian baru seperti varian alpha varian delta hingga beta terbanyak di indonesia berasal dari dki jakarta dengan total 1.327 kasus . ', 'corona di as mendadak naik lagi usai serangan delta sempat mereda jakarta - kasus covid-19 kembali naik di sejumlah wilayah amerika serikat as . padahal diketahui covid-19 sempat tercatat stabil pasca serangan varian delta musim panas ini. ada apa hal tersebut disampaikan oleh kepala penasihat medis gedung putih dr. anthony fauci senin 15 11 2021 . diketahui kasus nasional turun 57 persen minggu lalu dari puncak gelombang varian delta pada musim panas. namun jumlah pasien covid-19 di area barat tengah dan timur laut kini naik mendadak. ']\n"
     ]
    }
   ],
   "source": [
    "#path berita yang akan digunakan\n",
    "path = \"C:/Users/asus/bahan python/berita\"\n",
    "\n",
    "#memasukkan semua berita yang akan digunakan\n",
    "corpus = [] #menyediakan list kosong untuk berita\n",
    "\n",
    "for file in os.listdir(path): \n",
    "    with open(os.path.join(path, file), 'r') as f:\n",
    "        clean_txt = re.sub(\"http\\S+\", ' ', f.read()) #menggantikan bentuk link (\"https\") menjadi \"\"\n",
    "        clean_txt = re.sub(\"[\\n\\n]\", ' ', clean_txt) #menggantikan double new line dengan ' '\n",
    "        clean_txt = re.sub(r'[^a-zA-Z0-9 .-]',' ',clean_txt) #menggantikan semua karakter kecuali hypen(-) dan titik (.) ke ' '\n",
    "        clean_txt = re.sub(r\"\\s+\", ' ', clean_txt) #menggatikan white space berlebih dengan ' '\n",
    "        corpus.append(clean_txt.lower()) #menambahkan fungsi clean_text (yang telah dilakukan perlakuan) ke corpus dan CASE-FOLDING (lowercase)\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40a91570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenisasi(text):\n",
    "    corpus_term = [] #menyediakan list baru sebagai tempat hasil tokenisasi\n",
    "    nlp = Indonesian() #NLP bahasa\n",
    "    \n",
    "    for doc in text:\n",
    "        spacy_id = nlp(doc)\n",
    "        token_word = [token.text for token in spacy_id] #mentokenisasi text\n",
    "        corpus_term.append(token_word) #hasil tokenisasi ditambahkan pada list corpus_term\n",
    "    return corpus_term\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0929c3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwords_elimination(text):\n",
    "    nlp = Indonesian()\n",
    "    stopwords = nlp.Defaults.stop_words #mengidentifikasi kata-kata stopwords \n",
    "    \n",
    "    corpus_term =[] #menyediakan list kosong untuk hasil corpus_stopword\n",
    "    corpus_stopword = [] #menyediakan list kosong untuk kata-kata hasil eliminasi stopword\n",
    "    \n",
    "    for doc in range(len(text)):\n",
    "        corpus_stopword = [w for w in text[doc] if w not in stopwords] #proses elminasi stopword\n",
    "        corpus_term.append(corpus_stopword) #menambahkan list corpus_stopword ke list corpus_term\n",
    "    return corpus_term\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20b2cf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(text):\n",
    "    from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "    stemmer_text = StemmerFactory().create_stemmer() #membuat stemmer word\n",
    "    \n",
    "    corpus_term = [] #menyediakan list kosong untuk hasil corpus_stem\n",
    "    corpus_stem = [] #menyediakan list kosong untuk kata-kata setelah proses stemming\n",
    "    \n",
    "    for doc in text:\n",
    "        for w in doc:\n",
    "            corpus_stem.append(stemmer_text.stem(w))\n",
    "        corpus_term.append(corpus_stem)\n",
    "        corpus_stem=[]\n",
    "    return corpus_term    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00fe1a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_list = {\"kab\" : \"kabupaten\",\"aq\":\"aku\",\"kmu\":\"kamu\",\"lagi\":\"sedang\"}\n",
    "#normal list sendiri tidak terlalu terpakai untuk berita, karena berita tidak mengalami typo dan kamus slang lainnya\n",
    "\n",
    "def normalize(text):\n",
    "    corpus_term = []\n",
    "    \n",
    "    for doc in range(len(text)):\n",
    "        corpus_term.append([]) #menyediakan list kosong untuk kata yang akan di normalisasi\n",
    "        for w in text[doc]:\n",
    "            if (w != ''): #untuk string bukan '' akan ditambahkan kata yg dinormalisasi\n",
    "                corpus_term[doc].append(normal_list[w] if w in normal_list else w)\n",
    "    return corpus_term       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7c09084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['wilayah', 'bebas', 'covid', '-', '19', 'cek', '34', 'kabupaten', 'kota', 'zona', 'hijau', 'baru', 'jakarta', '-', 'perintah', 'rencana', 'terap', 'laku', 'batas', 'giat', 'masyarakat', 'ppkm', 'level', '3', 'hitung', '24', 'desember', '2021', '2', 'januari', '2021', 'menteri', 'sehat', 'ri', 'bijak', 'ppkm', 'level', '3', 'tahap', 'kaji', 'direktur', 'cegah', 'kendali', 'sakit', 'tular', 'langsung', 'p2pml', 'kemenkes', 'ri', 'dr', 'siti', 'nadia', 'tarmizi', 'ppkm', 'level', '3', 'terap', 'covid', '-', '19', 'signifikan', 'picu', 'tingkat', 'mobilitas', 'longgar', 'protokol', 'sehat'], ['vaksin', 'covid', '-', '19', 'rutin', 'gantung', 'jelas', 'jakarta', '-', 'beri', 'booster', 'dosis', 'tiga', 'vaksin', 'covid', '-', '19', 'indonesia', 'rencana', 'januari', '2022', 'lantas', 'ada', 'vaksinasi', 'covid', '-', '19', 'vaksinasi', 'influenza', 'ketua', 'satgas', 'covid', '-', '19', 'ikat', 'dokter', 'indonesia', 'idi', 'prof', 'zubairi', 'djoerban', 'pasti', 'kait', 'turut', 'vaksin', 'covid', '-', '19', 'booster', 'vaksinasi', 'covid', '-', '19'], ['ri', 'suntik', 'booster', '2022', 'ampuh', 'lawan', 'varian', 'delta', 'cs', 'jakarta', '-', 'pakar', 'aku', 'vaksin', '-', 'vaksin', 'dosis', '1', '-', '2', 'alami', 'turun', 'efektivitas', 'varian', 'corona', 'varian', 'delta', 'booster', 'dosis', 'tiga', 'vaksin', 'covid', '-', '19', 'indonesia', '2022', 'jenis', 'vaksin', 'ikut', 'strain', 'virus', 'baru', 'ketua', 'satgas', 'covid', '-', '19', 'ikat', 'dokter', 'indonesia', 'idi', 'prof', 'zubairi', 'djoerban', 'singgung', 'riset', 'kait', 'efektivitas', 'vaksin', 'covid', '-', '19', 'dosis', '1', '2', 'sebut', 'dasar', 'riset', 'efektivitas', 'vaksin', 'covid', '-', '19', 'pfizer', 'moderna', 'bukti', 'turun', 'lawan', 'varian', 'delta'], ['alert', 'varian', 'delta', 'covid', '-', '19', 'dki', 'tingkat', 'jakarta', '-', 'data', 'baru', 'balitbangkes', 'kemenkes', 'ri', '13', 'november', 'tambah', 'varian', 'delta', 'tambah', 'jawa', 'barat', '165', 'dki', 'jakarta', '90', 'sulawesi', 'utara', '86', 'balitbangkes', 'dki', 'jakarta', 'alami', 'tingkat', 'varian', 'delta', 'signifikan', 'varian', 'varian', 'alpha', 'varian', 'delta', 'beta', 'indonesia', 'asal', 'dki', 'jakarta', 'total', '1 327'], ['corona', 'as', 'dadak', 'serang', 'delta', 'reda', 'jakarta', '-', 'covid', '-', '19', 'wilayah', 'amerika', 'serikat', 'as', 'covid', '-', '19', 'catat', 'stabil', 'pasca', 'serang', 'varian', 'delta', 'musim', 'panas', 'kepala', 'nasihat', 'medis', 'gedung', 'putih', 'dr', 'anthony', 'fauci', 'senin', '15', '11', '2021', 'nasional', 'turun', '57', 'persen', 'minggu', 'puncak', 'gelombang', 'varian', 'delta', 'musim', 'panas', 'pasien', 'covid', '-', '19', 'area', 'barat', 'timur', 'laut', 'dadak']]\n"
     ]
    }
   ],
   "source": [
    "#Menjalankan semua fungsi text preprocessing\n",
    "#proses case-folding telah dilakukan saat pengentrian text berita\n",
    "\n",
    "corpus = tokenisasi(corpus) #menjalankan proses tokenisasi\n",
    "corpus = stopwords_elimination(corpus) #menjalankan proses eliminasi stopwords\n",
    "corpus = stemming(corpus) #menjalankan proses stemming\n",
    "corpus = normalize(corpus) #menjalankan proses normalisasi\n",
    "print(corpus)   \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d97be94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#membuat stemming untuk item di ivnverted index\n",
    "def stemming_index(corpus) :\n",
    "    # Stemming\n",
    "    # import StemmerFactory class\n",
    "    from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "    # create stemmer\n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    "\n",
    "    # stemming process\n",
    "    output   = stemmer.stem(corpus)\n",
    "    #for i in corpus :\n",
    "    #    for word in i :\n",
    "    #        output.append(stemmer.stem(word))\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5f874fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wilayah': [1, 5], 'bebas': [1], 'covid': [1, 2, 3, 4, 5], '-': [1, 2, 3, 4, 5], '19': [1, 2, 3, 4, 5], 'cek': [1], '34': [1], 'kabupaten': [1], 'kota': [1], 'zona': [1], 'hijau': [1], 'baru': [1, 3, 4], 'jakarta': [1, 2, 3, 4, 5], 'perintah': [1], 'rencana': [1, 2], 'terap': [1], 'laku': [1], 'batas': [1], 'giat': [1], 'masyarakat': [1], 'ppkm': [1], 'level': [1], '3': [1], 'hitung': [1], '24': [1], 'desember': [1], '2021': [1, 5], '2': [1, 3], 'januari': [1, 2], 'menteri': [1], 'sehat': [1], 'ri': [1, 3, 4], 'bijak': [1], 'tahap': [1], 'kaji': [1], 'direktur': [1], 'cegah': [1], 'kendali': [1], 'sakit': [1], 'tular': [1], 'langsung': [1], 'p2pml': [1], 'kemenkes': [1, 4], 'dr': [1, 5], 'siti': [1], 'nadia': [1], 'tarmizi': [1], 'signifikan': [1, 4], 'picu': [1], 'tingkat': [1, 4], 'mobilitas': [1], 'longgar': [1], 'protokol': [1], 'vaksin': [2, 3], 'rutin': [2], 'gantung': [2], 'jelas': [2], 'beri': [2], 'booster': [2, 3], 'dosis': [2, 3], 'tiga': [2, 3], 'indonesia': [2, 3, 4], '2022': [2, 3], 'lantas': [2], 'ada': [2], 'vaksinasi': [2], 'influenza': [2], 'ketua': [2, 3], 'satgas': [2, 3], 'ikat': [2, 3], 'dokter': [2, 3], 'idi': [2, 3], 'prof': [2, 3], 'zubairi': [2, 3], 'djoerban': [2, 3], 'pasti': [2], 'kait': [2, 3], 'turut': [2], 'suntik': [3], 'ampuh': [3], 'lawan': [3], 'varian': [3, 4, 5], 'delta': [3, 4, 5], 'cs': [3], 'pakar': [3], 'aku': [3], '1': [3], 'alami': [3, 4], 'turun': [3, 5], 'efektivitas': [3], 'corona': [3, 5], 'jenis': [3], 'ikut': [3], 'strain': [3], 'virus': [3], 'singgung': [3], 'riset': [3], 'sebut': [3], 'dasar': [3], 'pfizer': [3], 'moderna': [3], 'bukti': [3], 'alert': [4], 'dki': [4], 'data': [4], 'balitbangkes': [4], '13': [4], 'november': [4], 'tambah': [4], 'jawa': [4], 'barat': [4, 5], '165': [4], '90': [4], 'sulawesi': [4], 'utara': [4], '86': [4], 'alpha': [4], 'beta': [4], 'asal': [4], 'total': [4], '1 327': [4], 'as': [5], 'dadak': [5], 'serang': [5], 'reda': [5], 'amerika': [5], 'serikat': [5], 'catat': [5], 'stabil': [5], 'pasca': [5], 'musim': [5], 'panas': [5], 'kepala': [5], 'nasihat': [5], 'medis': [5], 'gedung': [5], 'putih': [5], 'anthony': [5], 'fauci': [5], 'senin': [5], '15': [5], '11': [5], 'nasional': [5], '57': [5], 'persen': [5], 'minggu': [5], 'puncak': [5], 'gelombang': [5], 'pasien': [5], 'area': [5], 'timur': [5], 'laut': [5]}\n"
     ]
    }
   ],
   "source": [
    "#INVERTED INDEX\n",
    "# mendapatkan inverted index pada corpus di atas \n",
    "corpus = corpus\n",
    "inverted_index = {}\n",
    " \n",
    "for i in range(len(corpus)):\n",
    "    for item in corpus[i]: \n",
    "        item = stemming_index(item)\n",
    "        if item not in inverted_index:\n",
    "            inverted_index[item] = []\n",
    "        if (item in inverted_index) and ((i+1) not in inverted_index[item]):\n",
    "            inverted_index[item].append(i+1)\n",
    "print(inverted_index)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf382dc",
   "metadata": {},
   "source": [
    "## FUNGSI AND, OR, NOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7ff67a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class BooleanModel():\n",
    "\n",
    "        @staticmethod\n",
    "        def and_operation(left_operand, right_operand):\n",
    "            # perform 'merge'\n",
    "            result = [] # results list to be returned\n",
    "            l_index = 0 # current index in left_operand\n",
    "            r_index = 0 # current index in right_operand\n",
    "            l_skip = int(math.sqrt(len(left_operand)))\n",
    "            # skip pointer distance for l_index\n",
    "            r_skip = int(math.sqrt(len(right_operand)))\n",
    "            # skip pointer distance for r_index\n",
    "\n",
    "            while (l_index < len(left_operand) and r_index < len(right_operand)):\n",
    "                l_item = left_operand[l_index]\n",
    "                r_item = right_operand[r_index]\n",
    "\n",
    "                # case 1: if match\n",
    "                if (l_item == r_item):\n",
    "                    result.append(l_item) # add to results\n",
    "                    l_index += 1 # advance left index\n",
    "                    r_index += 1 # advance right index\n",
    "\n",
    "                # case 2: if left item is more than right item\n",
    "                elif (l_item > r_item):\n",
    "                    # if r_index can be skipped (if new r_index is still within range and resulting item is <= left item)\n",
    "                    if (r_index + r_skip < len(right_operand)) and right_operand[r_index + r_skip] <= l_item:\n",
    "                        r_index += r_skip\n",
    "                    # else advance r_index by 1\n",
    "                    else:\n",
    "                        r_index += 1\n",
    "                \n",
    "                # case 3: if left item is less than right item\n",
    "                else:\n",
    "                    # if l_index can be skipped (if new l_index is still within range and resulting item is <= right item)\n",
    "                    if (l_index + l_skip < len(left_operand)) and left_operand[l_index + l_skip] <= r_item:\n",
    "                        l_index += l_skip\n",
    "                    # else advance l_index by 1\n",
    "                    else:\n",
    "                        l_index += 1\n",
    "            return result\n",
    "\n",
    "        @staticmethod\n",
    "        def or_operation(left_operand, right_operand):\n",
    "            result = [] # union of left and right operand\n",
    "            l_index = 0 # current index in left_operand\n",
    "            r_index = 0 # current index in right_operand\n",
    "            # while lists have not yet been covered\n",
    "            while (l_index < len(left_operand) or r_index < len(right_operand)):\n",
    "                # if both list are not yet exhausted\n",
    "                if (l_index < len(left_operand) and r_index < len(right_operand)):\n",
    "                    l_item = left_operand[l_index] # current item in left_operand\n",
    "                    r_item = right_operand[r_index] # current item in right_operand\n",
    "                    \n",
    "                    # case 1: if items are equal, add either one to result and advance both pointers\n",
    "                    if (l_item == r_item):\n",
    "                        result.append(l_item)\n",
    "                        l_index += 1\n",
    "                        r_index += 1\n",
    "\n",
    "                    # case 2: l_item greater than r_item, add r_item and advance r_index\n",
    "                    elif (l_item > r_item):\n",
    "                        result.append(r_item)\n",
    "                        r_index += 1\n",
    "\n",
    "                    # case 3: l_item lower than r_item, add l_item and advance l_index\n",
    "                    else:\n",
    "                        result.append(l_item)\n",
    "                        l_index += 1\n",
    "\n",
    "                    # if left_operand list is exhausted, append r_item and advance r_index\n",
    "                elif (l_index >= len(left_operand)):\n",
    "                    r_item = right_operand[r_index]\n",
    "                    result.append(r_item)\n",
    "                    r_index += 1\n",
    "                # else if right_operand list is exhausted, append l_item and advance l_index\n",
    "                else:\n",
    "                    l_item = left_operand[l_index]\n",
    "                    result.append(l_item)\n",
    "                    l_index += 1\n",
    "            return result\n",
    "\n",
    "        \n",
    "        @staticmethod\n",
    "        def not_operation(right_operand, indexed_docIDs):\n",
    "            # complement of an empty list is list of all indexed docIDs\n",
    "            if (not right_operand):\n",
    "                return indexed_docIDs\n",
    "            result = []\n",
    "            r_index = 0 # index for right operand\n",
    "            for item in indexed_docIDs:\n",
    "                # if item do not match that in right_operand, it belongs to compliment\n",
    "                if (item != right_operand[r_index]):\n",
    "                    result.append(item)\n",
    "                # else if item matches and r_index still can progress, advance it by 1\n",
    "                elif (r_index + 1 < len(right_operand)):\n",
    "                    r_index += 1\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef855da",
   "metadata": {},
   "source": [
    "## FUNGSI SORTING QUERY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "318d3d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_query(infix_tokens):\n",
    "    \"\"\" Parse Query\n",
    "    Parsing done using Shunting Yard Algorithm\n",
    "    \"\"\"\n",
    "    precedence = {}\n",
    "    precedence['NOT'] = 3\n",
    "    precedence['AND'] = 2\n",
    "    precedence['OR'] = 1\n",
    "    precedence['('] = 0\n",
    "    precedence[')'] = 0\n",
    "    \n",
    "    output = []\n",
    "    operator_stack = []\n",
    "    \n",
    "    for token in infix_tokens:\n",
    "        if (token == '('):\n",
    "            operator_stack.append(token)\n",
    "        # if right bracket, pop all operators from operator stack onto output until we hit left bracket\n",
    "        elif (token == ')'):\n",
    "            operator = operator_stack.pop()\n",
    "            while operator != '(':\n",
    "                output.append(operator)\n",
    "                operator = operator_stack.pop()\n",
    "        # if operator, pop operators from operator stack to queue if they are of higher precedence\n",
    "        elif (token in precedence):\n",
    "            # if operator stack is not empty\n",
    "            if (operator_stack):\n",
    "                current_operator = operator_stack[-1]\n",
    "                while (operator_stack and precedence[current_operator] > precedence[token]):\n",
    "                    output.append(operator_stack.pop())\n",
    "                    if (operator_stack):\n",
    "                        current_operator = operator_stack[-1]\n",
    "            operator_stack.append(token) # add token to stack\n",
    "        else:\n",
    "            output.append(token.lower())\n",
    "    # while there are still operators on the stack, pop them into the queue\n",
    "    while (operator_stack):\n",
    "        output.append(operator_stack.pop())\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1a0c1f",
   "metadata": {},
   "source": [
    "## FUNGSI BOOLEAN RETRIEVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "95aaf6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fungsi proses query untuk mengeksekusi query \n",
    "# terdapat beberapa parameter yang digunakan yaitu query itu sendri, \n",
    "# jumlah dokumen, dan inverted index yang telah dibuat sebelumnya\n",
    "\n",
    "import collections\n",
    "\n",
    "def process_query(query, n_docs, inverted_index):\n",
    "    # prepare query list\n",
    "    query = query.replace('(', '( ')\n",
    "    query = query.replace(')', ' )')\n",
    "    query = query.split(' ')\n",
    "    print(query)\n",
    "\n",
    "    indexed_docIDs = list(range(1, n_docs + 1))\n",
    "    results_stack = []\n",
    "    postfix_queue = collections.deque(parse_query(query)) # get query in postfix notation as a queue\n",
    "\n",
    "    while postfix_queue:\n",
    "        token = postfix_queue.popleft()\n",
    "        result = [] # the evaluated result at each stage\n",
    "        # if operand, add postings list for term to results stack\n",
    "        if (token != 'AND' and token != 'OR' and token != 'NOT'):\n",
    "            token = stemming_index(token) # stem the token\n",
    "            # default empty list if not in dictionary\n",
    "            if (token in inverted_index):\n",
    "                result = inverted_index[token]\n",
    "\n",
    "        elif (token == 'AND'):\n",
    "            right_operand = results_stack.pop()\n",
    "            left_operand = results_stack.pop()\n",
    "            result = BooleanModel.and_operation(left_operand, right_operand) # evaluate AND\n",
    "            \n",
    "        elif (token == 'OR'):\n",
    "            right_operand = results_stack.pop()\n",
    "            left_operand = results_stack.pop()\n",
    "            result = BooleanModel.or_operation(left_operand, right_operand) # evaluate OR\n",
    "\n",
    "        elif (token == 'NOT'):\n",
    "            right_operand = results_stack.pop()\n",
    "            result = BooleanModel.not_operation(right_operand, indexed_docIDs) # evaluate NOT\n",
    "        results_stack.append(result)\n",
    "\n",
    "    # NOTE: at this point results_stack should only have one item and it is the final result\n",
    "    if len(results_stack) != 1:\n",
    "        print(\"ERROR: Invalid Query. Please check query syntax.\") #check for errors\n",
    "        return None\n",
    "    return results_stack.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f49ebdc",
   "metadata": {},
   "source": [
    "### Contoh processing query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "69905cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['corona']\n",
      "[3, 5]\n",
      "['covid']\n",
      "[1, 2, 3, 4, 5]\n",
      "['vaksin']\n",
      "[2, 3]\n",
      "['corona', 'OR', 'covid']\n",
      "[1, 2, 3, 4, 5]\n",
      "['vaksin', 'AND', 'corona']\n",
      "[3]\n",
      "['vaksin', 'AND', '(', 'corona', 'OR', 'covid', ')']\n",
      "[2, 3]\n"
     ]
    }
   ],
   "source": [
    "print(process_query(\"corona\",len(corpus),inverted_index))\n",
    "\n",
    "print(process_query(\"covid\",len(corpus),inverted_index))\n",
    "\n",
    "print(process_query(\"vaksin\",len(corpus),inverted_index))\n",
    "\n",
    "print(process_query(\"corona OR covid\",len(corpus),inverted_index))\n",
    "\n",
    "print(process_query(\"vaksin AND corona\",len(corpus),inverted_index))\n",
    "\n",
    "print(process_query(\"vaksin AND (corona OR covid)\",len(corpus),inverted_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba003fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
