{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f80867ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'doc1': 'kembang sistem informasi jadwal', 'doc2': 'kembang model analisis sentimen berita', 'doc3': 'analisis sistem input output', 'doc4': 'kembang sistem informasi akademik universitas', 'doc5': 'kembang sistem cari berita ekonomi', 'doc6': 'analisis sistem neraca nasional', 'doc7': 'kembang sistem informasi layan statistik', 'doc8': 'kembang sistem cari skripsi di universitas', 'doc9': 'analisis sentimen publik hadap perintah', 'doc10': 'kembang model klasifikasi sentimen berita'}\n"
     ]
    }
   ],
   "source": [
    "def tokenisasi(text):\n",
    "    tokens = text.split(\" \")\n",
    "    return tokens\n",
    "\n",
    "def stemming(text):\n",
    "    from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "    #create stemmer\n",
    "    stemmer = StemmerFactory().create_stemmer()\n",
    "    #stemming process\n",
    "    output = stemmer.stem(text)\n",
    "    return output\n",
    "\n",
    "\n",
    "def stemming_sentence(text):\n",
    "    output = \"\"\n",
    "    for token in tokenisasi(text):\n",
    "        output = output + stemming(token) + \" \"\n",
    "    return output[:-1]\n",
    "\n",
    "doc_dict_raw = {}\n",
    "doc_dict_raw['doc1'] = \"pengembangan sistem informasi penjadwalan\"\n",
    "doc_dict_raw['doc2'] = \"pengembangan model analisis sentimen berita\"\n",
    "doc_dict_raw['doc3'] = \"analisis sistem input output\"\n",
    "doc_dict_raw['doc4'] = \"pengembangan sistem informasi akademik universitas\"\n",
    "doc_dict_raw['doc5'] = \"pengembangan sistem cari berita ekonomi\"\n",
    "doc_dict_raw['doc6'] = \"analisis sistem neraca nasional\"\n",
    "doc_dict_raw['doc7'] = \"pengembangan sistem informasi layanan statistik\"\n",
    "doc_dict_raw['doc8'] = \"pengembangan sistem pencarian skripsi di universitas\"\n",
    "doc_dict_raw['doc9'] = \"analisis sentimen publik terhadap pemerintah\"\n",
    "doc_dict_raw['doc10'] = \"pengembangan model klasifikasi sentimen berita\"\n",
    "\n",
    "doc_dict = {}\n",
    "for doc_id, doc in doc_dict_raw.items():\n",
    "    doc_dict[doc_id] = stemming_sentence(doc)\n",
    "print(doc_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92406933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kembang model klasifikasi sentimen berita'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2bc3c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kembang', 'sistem', 'informasi', 'jadwal', 'model', 'analisis', 'sentimen', 'berita', 'input', 'output', 'akademik', 'universitas', 'cari', 'ekonomi', 'neraca', 'nasional', 'layan', 'statistik', 'skripsi', 'di', 'publik', 'hadap', 'perintah', 'klasifikasi']\n",
      "{'kembang': ['doc1', 'doc2', 'doc4', 'doc5', 'doc7', 'doc8', 'doc10'], 'sistem': ['doc1', 'doc3', 'doc4', 'doc5', 'doc6', 'doc7', 'doc8'], 'informasi': ['doc1', 'doc4', 'doc7'], 'jadwal': ['doc1'], 'model': ['doc2', 'doc10'], 'analisis': ['doc2', 'doc3', 'doc6', 'doc9'], 'sentimen': ['doc2', 'doc9', 'doc10'], 'berita': ['doc2', 'doc5', 'doc10'], 'input': ['doc3'], 'output': ['doc3'], 'akademik': ['doc4'], 'universitas': ['doc4', 'doc8'], 'cari': ['doc5', 'doc8'], 'ekonomi': ['doc5'], 'neraca': ['doc6'], 'nasional': ['doc6'], 'layan': ['doc7'], 'statistik': ['doc7'], 'skripsi': ['doc8'], 'di': ['doc8'], 'publik': ['doc9'], 'hadap': ['doc9'], 'perintah': ['doc9'], 'klasifikasi': ['doc10']}\n"
     ]
    }
   ],
   "source": [
    "vocab = []\n",
    "\n",
    "inverted_index = {}\n",
    "\n",
    "for doc_id, doc in doc_dict.items():\n",
    "    for token in tokenisasi(doc):\n",
    "        if token not in vocab:\n",
    "            vocab.append(token)\n",
    "            inverted_index[token] = []\n",
    "        if token in inverted_index:\n",
    "            if doc_id not in inverted_index[token]:\n",
    "                inverted_index[token].append(doc_id)\n",
    "print(vocab)\n",
    "print(inverted_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26b03c0",
   "metadata": {},
   "source": [
    "# EXACT TOP K Document Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac8ebb5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kembang': 0, 'sistem': 1, 'informasi': 1, 'jadwal': 0, 'model': 0, 'analisis': 0, 'sentimen': 0, 'berita': 0, 'input': 0, 'output': 0, 'akademik': 0, 'universitas': 0, 'cari': 0, 'ekonomi': 0, 'neraca': 0, 'nasional': 0, 'layan': 0, 'statistik': 1, 'skripsi': 0, 'di': 0, 'publik': 0, 'hadap': 0, 'perintah': 0, 'klasifikasi': 0}\n"
     ]
    }
   ],
   "source": [
    "#Untuk penghitungan apakah terdapat kata di query yang terdapat di inverted index\n",
    "\n",
    "query = \"sistem informasi statistik\"\n",
    "def termFrequency(vocab, query):\n",
    "    tf_query = {}\n",
    "    for word in vocab:\n",
    "        tf_query[word] = query.count(word)\n",
    "    return tf_query\n",
    "\n",
    "tf_query = termFrequency(vocab,query)\n",
    "\n",
    "print(tf_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41321e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kembang': 7, 'sistem': 7, 'informasi': 3, 'jadwal': 1, 'model': 2, 'analisis': 4, 'sentimen': 3, 'berita': 3, 'input': 1, 'output': 1, 'akademik': 1, 'universitas': 2, 'cari': 2, 'ekonomi': 1, 'neraca': 1, 'nasional': 1, 'layan': 1, 'statistik': 1, 'skripsi': 1, 'di': 1, 'publik': 1, 'hadap': 1, 'perintah': 1, 'klasifikasi': 1}\n"
     ]
    }
   ],
   "source": [
    "def wordDocFre(vocab, doc_dict):\n",
    "    df = {}\n",
    "    for word in vocab:\n",
    "        frq = 0\n",
    "        for doc in doc_dict.values():\n",
    "            if word in tokenisasi(doc):\n",
    "                frq = frq + 1\n",
    "        df[word] = frq\n",
    "    return df\n",
    "print(wordDocFre(vocab, doc_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df3810b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kembang': 7, 'sistem': 7, 'informasi': 3, 'jadwal': 1, 'model': 2, 'analisis': 4, 'sentimen': 3, 'berita': 3, 'input': 1, 'output': 1, 'akademik': 1, 'universitas': 2, 'cari': 2, 'ekonomi': 1, 'neraca': 1, 'nasional': 1, 'layan': 1, 'statistik': 1, 'skripsi': 1, 'di': 1, 'publik': 1, 'hadap': 1, 'perintah': 1, 'klasifikasi': 1}\n",
      "{'doc1': {'kembang': 1.3184537311185345, 'sistem': 1.3184537311185345, 'informasi': 2.01160091167848, 'jadwal': 2.7047480922384253, 'model': 0.0, 'analisis': 0.0, 'sentimen': 0.0, 'berita': 0.0, 'input': 0.0, 'output': 0.0, 'akademik': 0.0, 'universitas': 0.0, 'cari': 0.0, 'ekonomi': 0.0, 'neraca': 0.0, 'nasional': 0.0, 'layan': 0.0, 'statistik': 0.0, 'skripsi': 0.0, 'di': 0.0, 'publik': 0.0, 'hadap': 0.0, 'perintah': 0.0, 'klasifikasi': 0.0}, 'doc2': {'kembang': 1.3184537311185345, 'sistem': 0.0, 'informasi': 0.0, 'jadwal': 0.0, 'model': 2.2992829841302607, 'analisis': 1.7884573603642702, 'sentimen': 2.01160091167848, 'berita': 2.01160091167848, 'input': 0.0, 'output': 0.0, 'akademik': 0.0, 'universitas': 0.0, 'cari': 0.0, 'ekonomi': 0.0, 'neraca': 0.0, 'nasional': 0.0, 'layan': 0.0, 'statistik': 0.0, 'skripsi': 0.0, 'di': 0.0, 'publik': 0.0, 'hadap': 0.0, 'perintah': 0.0, 'klasifikasi': 0.0}, 'doc3': {'kembang': 0.0, 'sistem': 1.3184537311185345, 'informasi': 0.0, 'jadwal': 0.0, 'model': 0.0, 'analisis': 1.7884573603642702, 'sentimen': 0.0, 'berita': 0.0, 'input': 2.7047480922384253, 'output': 2.7047480922384253, 'akademik': 0.0, 'universitas': 0.0, 'cari': 0.0, 'ekonomi': 0.0, 'neraca': 0.0, 'nasional': 0.0, 'layan': 0.0, 'statistik': 0.0, 'skripsi': 0.0, 'di': 0.0, 'publik': 0.0, 'hadap': 0.0, 'perintah': 0.0, 'klasifikasi': 0.0}, 'doc4': {'kembang': 1.3184537311185345, 'sistem': 1.3184537311185345, 'informasi': 2.01160091167848, 'jadwal': 0.0, 'model': 0.0, 'analisis': 0.0, 'sentimen': 0.0, 'berita': 0.0, 'input': 0.0, 'output': 0.0, 'akademik': 2.7047480922384253, 'universitas': 2.2992829841302607, 'cari': 0.0, 'ekonomi': 0.0, 'neraca': 0.0, 'nasional': 0.0, 'layan': 0.0, 'statistik': 0.0, 'skripsi': 0.0, 'di': 0.0, 'publik': 0.0, 'hadap': 0.0, 'perintah': 0.0, 'klasifikasi': 0.0}, 'doc5': {'kembang': 1.3184537311185345, 'sistem': 1.3184537311185345, 'informasi': 0.0, 'jadwal': 0.0, 'model': 0.0, 'analisis': 0.0, 'sentimen': 0.0, 'berita': 2.01160091167848, 'input': 0.0, 'output': 0.0, 'akademik': 0.0, 'universitas': 0.0, 'cari': 2.2992829841302607, 'ekonomi': 2.7047480922384253, 'neraca': 0.0, 'nasional': 0.0, 'layan': 0.0, 'statistik': 0.0, 'skripsi': 0.0, 'di': 0.0, 'publik': 0.0, 'hadap': 0.0, 'perintah': 0.0, 'klasifikasi': 0.0}, 'doc6': {'kembang': 0.0, 'sistem': 1.3184537311185345, 'informasi': 0.0, 'jadwal': 0.0, 'model': 0.0, 'analisis': 1.7884573603642702, 'sentimen': 0.0, 'berita': 0.0, 'input': 0.0, 'output': 0.0, 'akademik': 0.0, 'universitas': 0.0, 'cari': 0.0, 'ekonomi': 0.0, 'neraca': 2.7047480922384253, 'nasional': 2.7047480922384253, 'layan': 0.0, 'statistik': 0.0, 'skripsi': 0.0, 'di': 0.0, 'publik': 0.0, 'hadap': 0.0, 'perintah': 0.0, 'klasifikasi': 0.0}, 'doc7': {'kembang': 1.3184537311185345, 'sistem': 1.3184537311185345, 'informasi': 2.01160091167848, 'jadwal': 0.0, 'model': 0.0, 'analisis': 0.0, 'sentimen': 0.0, 'berita': 0.0, 'input': 0.0, 'output': 0.0, 'akademik': 0.0, 'universitas': 0.0, 'cari': 0.0, 'ekonomi': 0.0, 'neraca': 0.0, 'nasional': 0.0, 'layan': 2.7047480922384253, 'statistik': 2.7047480922384253, 'skripsi': 0.0, 'di': 0.0, 'publik': 0.0, 'hadap': 0.0, 'perintah': 0.0, 'klasifikasi': 0.0}, 'doc8': {'kembang': 1.3184537311185345, 'sistem': 1.3184537311185345, 'informasi': 0.0, 'jadwal': 0.0, 'model': 0.0, 'analisis': 0.0, 'sentimen': 0.0, 'berita': 0.0, 'input': 0.0, 'output': 0.0, 'akademik': 0.0, 'universitas': 2.2992829841302607, 'cari': 2.2992829841302607, 'ekonomi': 0.0, 'neraca': 0.0, 'nasional': 0.0, 'layan': 0.0, 'statistik': 0.0, 'skripsi': 2.7047480922384253, 'di': 2.7047480922384253, 'publik': 0.0, 'hadap': 0.0, 'perintah': 0.0, 'klasifikasi': 0.0}, 'doc9': {'kembang': 0.0, 'sistem': 0.0, 'informasi': 0.0, 'jadwal': 0.0, 'model': 0.0, 'analisis': 1.7884573603642702, 'sentimen': 2.01160091167848, 'berita': 0.0, 'input': 0.0, 'output': 0.0, 'akademik': 0.0, 'universitas': 0.0, 'cari': 0.0, 'ekonomi': 0.0, 'neraca': 0.0, 'nasional': 0.0, 'layan': 0.0, 'statistik': 0.0, 'skripsi': 0.0, 'di': 0.0, 'publik': 2.7047480922384253, 'hadap': 2.7047480922384253, 'perintah': 2.7047480922384253, 'klasifikasi': 0.0}, 'doc10': {'kembang': 1.3184537311185345, 'sistem': 0.0, 'informasi': 0.0, 'jadwal': 0.0, 'model': 2.2992829841302607, 'analisis': 0.0, 'sentimen': 2.01160091167848, 'berita': 2.01160091167848, 'input': 0.0, 'output': 0.0, 'akademik': 0.0, 'universitas': 0.0, 'cari': 0.0, 'ekonomi': 0.0, 'neraca': 0.0, 'nasional': 0.0, 'layan': 0.0, 'statistik': 0.0, 'skripsi': 0.0, 'di': 0.0, 'publik': 0.0, 'hadap': 0.0, 'perintah': 0.0, 'klasifikasi': 2.7047480922384253}}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def inverseDocFre(vocab, doc_fre,length):\n",
    "    idf = {}\n",
    "    for word in vocab:\n",
    "        idf[word] = idf[word] = 1+ np.log((length + 1)/(doc_fre[word]+1))\n",
    "    return idf\n",
    "\n",
    "def termFrequencyInDoc(vocab, doc_dict):\n",
    "    tf_docs = {}\n",
    "    for doc_id in doc_dict.keys():\n",
    "        tf_docs[doc_id] = {}\n",
    "    for word in vocab:\n",
    "        for doc_id,doc in doc_dict.items():\n",
    "            tf_docs[doc_id][word] = doc.count(word)\n",
    "    return tf_docs\n",
    "\n",
    "def tfidf(vocab, tf, idf_scr, doc_dict):\n",
    "    tf_idf_scr = {}\n",
    "    for doc_id in doc_dict.keys():\n",
    "        tf_idf_scr[doc_id] = {}\n",
    "    for word in vocab:\n",
    "        for doc_id,doc in doc_dict.items():\n",
    "            tf_idf_scr[doc_id][word] = tf[doc_id][word] * idf_scr[word]\n",
    "    return tf_idf_scr\n",
    "\n",
    "\n",
    "tf_idf = tfidf(vocab, termFrequencyInDoc(vocab, doc_dict), inverseDocFre(vocab, wordDocFre(vocab, doc_dict),len(doc_dict)), doc_dict)\n",
    "print(tf_idf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a7be52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'doc1': 'kembang sistem informasi jadwal', 'doc2': 'kembang model analisis sentimen berita', 'doc3': 'analisis sistem input output', 'doc4': 'kembang sistem informasi akademik universitas', 'doc5': 'kembang sistem cari berita ekonomi', 'doc6': 'analisis sistem neraca nasional', 'doc7': 'kembang sistem informasi layan statistik', 'doc8': 'kembang sistem cari skripsi di universitas', 'doc9': 'analisis sentimen publik hadap perintah', 'doc10': 'kembang model klasifikasi sentimen berita'}\n"
     ]
    }
   ],
   "source": [
    "print(doc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baf8f2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.31845373 1.31845373 0.         1.31845373 1.31845373 0.\n",
      "  1.31845373 1.31845373 0.         1.31845373]\n",
      " [1.31845373 0.         1.31845373 1.31845373 1.31845373 1.31845373\n",
      "  1.31845373 1.31845373 0.         0.        ]\n",
      " [2.01160091 0.         0.         2.01160091 0.         0.\n",
      "  2.01160091 0.         0.         0.        ]\n",
      " [2.70474809 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         2.29928298 0.         0.         0.         0.\n",
      "  0.         0.         0.         2.29928298]\n",
      " [0.         1.78845736 1.78845736 0.         0.         1.78845736\n",
      "  0.         0.         1.78845736 0.        ]\n",
      " [0.         2.01160091 0.         0.         0.         0.\n",
      "  0.         0.         2.01160091 2.01160091]\n",
      " [0.         2.01160091 0.         0.         2.01160091 0.\n",
      "  0.         0.         0.         2.01160091]\n",
      " [0.         0.         2.70474809 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         2.70474809 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         2.70474809 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         2.29928298 0.         0.\n",
      "  0.         2.29928298 0.         0.        ]\n",
      " [0.         0.         0.         0.         2.29928298 0.\n",
      "  0.         2.29928298 0.         0.        ]\n",
      " [0.         0.         0.         0.         2.70474809 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         2.70474809\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         2.70474809\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  2.70474809 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  2.70474809 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         2.70474809 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         2.70474809 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         2.70474809 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         2.70474809 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         2.70474809 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         2.70474809]]\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "# Term - Document, Matrix\n",
    "\n",
    "TD = np.zeros((len(vocab),len(doc_dict)))\n",
    "for word in vocab:\n",
    "    for doc_id, doc in tf_idf.items():\n",
    "        ind1 = vocab.index(word)\n",
    "        ind2 = list(tf_idf.keys()).index(doc_id)\n",
    "        TD[ind1][ind2] = tf_idf[doc_id][word]\n",
    "print(TD)\n",
    "print(len(TD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e913eba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.        ]\n",
      " [1.31845373]\n",
      " [2.01160091]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [2.70474809]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]]\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "#Term - Query Matrix\n",
    "import numpy as np\n",
    "\n",
    "idf = inverseDocFre(vocab, wordDocFre(vocab, doc_dict),len(doc_dict))\n",
    "\n",
    "\n",
    "TQ = np.zeros((len(vocab),1)) #hanya 1 query\n",
    "for word in vocab:\n",
    "    ind1 = vocab.index(word)\n",
    "    TQ[ind1][0] = tf_query[word]*idf[word]\n",
    "print(TQ)\n",
    "print(len(TQ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1473af20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#COSINE SIMILARITY\n",
    "\n",
    "import math\n",
    "def cosine_sim(vec1, vec2):\n",
    "    vec1 = list(vec1)\n",
    "    vec2 = list(vec2)\n",
    "    dot_prod = 0\n",
    "    for i, v in enumerate (vec1):\n",
    "        dot_prod += v * vec2[i]\n",
    "    mag_1 = math.sqrt(sum([x**2 for x in vec1]))\n",
    "    mag_2 = math.sqrt(sum([x**2 for x in vec2]))\n",
    "    \n",
    "    return dot_prod / (mag_1*mag_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae3a641e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.414904809442661\n",
      "0.0\n",
      "0.10856998991379904\n"
     ]
    }
   ],
   "source": [
    "print(cosine_sim(TQ[:, 0], TD[:, 0])) #query & doc1\n",
    "print(cosine_sim(TQ[:, 0], TD[:, 1])) #query & doc2\n",
    "print(cosine_sim(TQ[:, 0], TD[:, 2])) #query & doc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98cc7a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "def exact_top_k(doc_dict, TD, q, k):\n",
    "    relevance_scores = {}\n",
    "    i = 0\n",
    "    for doc_id in doc_dict.keys():\n",
    "        relevance_scores[doc_id] = cosine_sim(q, TD[:, i])\n",
    "        i = i+1\n",
    "    \n",
    "    sorted_value = OrderedDict(sorted(relevance_scores.items(), key = lambda x: x[1], reverse = True))\n",
    "    top_k = {j: sorted_value[j] for j in list(sorted_value)[:k]}\n",
    "    return top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ef90ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc7': 0.7689768599816609,\n",
       " 'doc1': 0.414904809442661,\n",
       " 'doc4': 0.35626622628022314}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_3 = exact_top_k(doc_dict, TD, TQ[:, 0], 3)\n",
    "top_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f3fdb7",
   "metadata": {},
   "source": [
    "### Inexact Top K Document Retrieval (Scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f77d3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_elim_simple(query, doc_dict):\n",
    "    remove_list =[]\n",
    "    for doc_id,doc in doc_dict.items():\n",
    "        n = 0\n",
    "        for word in tokenisasi(query):\n",
    "            if stemming(word) in doc:\n",
    "                n = n+1\n",
    "        if n==0:\n",
    "            remove_list.append(doc_id)\n",
    "    for key in remove_list:\n",
    "        del doc_dict[key]\n",
    "    return doc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33c7ca40",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"sistem informasi statistik\"\n",
    "doc_dict = index_elim_simple(query, doc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b2447bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elim_query(query, idf_dict, idf_scores):\n",
    "    for term in tokenisasi(query):\n",
    "        if idf_dict[stemming(term)] < idf_scores:\n",
    "            query = query.replace(term+\" \", \"\")\n",
    "            query = query.replace(term, \"\")\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bd82dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "informasi statistik\n"
     ]
    }
   ],
   "source": [
    "query = \"sistem informasi statistik\"\n",
    "query = elim_query(query, idf, 1.5)\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376f90db",
   "metadata": {},
   "source": [
    "# Champion List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a449b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_championlist(inverted_index, tf_idf, r):\n",
    "    champion_list = {}\n",
    "    for term in inverted_index.keys():\n",
    "        weight_scores = {}\n",
    "        for doc_id,tf in tf_idf.items():\n",
    "            if tf_idf[doc_id][term]!=0:\n",
    "                weight_scores[doc_id] = tf_idf[doc_id][term]\n",
    "                sorted_value = OrderedDict(sorted(weight_scores.items(), key=lambda x: x[1], reverse = True))\n",
    "                top_r = {j: sorted_value[j] for j in list(sorted_value)[:r]}\n",
    "                champion_list[term]=list(top_r.keys())\n",
    "    return champion_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c29b597f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kembang': ['doc1', 'doc2'],\n",
       " 'sistem': ['doc1', 'doc3'],\n",
       " 'informasi': ['doc1', 'doc4'],\n",
       " 'jadwal': ['doc1'],\n",
       " 'model': ['doc2', 'doc10'],\n",
       " 'analisis': ['doc2', 'doc3'],\n",
       " 'sentimen': ['doc2', 'doc9'],\n",
       " 'berita': ['doc2', 'doc5'],\n",
       " 'input': ['doc3'],\n",
       " 'output': ['doc3'],\n",
       " 'akademik': ['doc4'],\n",
       " 'universitas': ['doc4', 'doc8'],\n",
       " 'cari': ['doc5', 'doc8'],\n",
       " 'ekonomi': ['doc5'],\n",
       " 'neraca': ['doc6'],\n",
       " 'nasional': ['doc6'],\n",
       " 'layan': ['doc7'],\n",
       " 'statistik': ['doc7'],\n",
       " 'skripsi': ['doc8'],\n",
       " 'di': ['doc8'],\n",
       " 'publik': ['doc9'],\n",
       " 'hadap': ['doc9'],\n",
       " 'perintah': ['doc9'],\n",
       " 'klasifikasi': ['doc10']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = 2\n",
    "create_championlist(inverted_index, tf_idf, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ae7da9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
