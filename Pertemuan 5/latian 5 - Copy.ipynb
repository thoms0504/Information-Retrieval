{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f80867ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'doc1': 'kembang sistem informasi jadwal', 'doc2': 'kembang model analisis sentimen berita', 'doc3': 'analisis sistem input output', 'doc4': 'kembang sistem informasi akademik universitas', 'doc5': 'kembang sistem cari berita ekonomi', 'doc6': 'analisis sistem neraca nasional', 'doc7': 'kembang sistem informasi layan statistik', 'doc8': 'kembang sistem cari skripsi di universitas', 'doc9': 'analisis sentimen publik hadap perintah', 'doc10': 'kembang model klasifikasi sentimen berita'}\n"
     ]
    }
   ],
   "source": [
    "def tokenisasi(text):\n",
    "    tokens = text.split(\" \")\n",
    "    return tokens\n",
    "\n",
    "def stemming(text):\n",
    "    from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "    #create stemmer\n",
    "    stemmer = StemmerFactory().create_stemmer()\n",
    "    #stemming process\n",
    "    output = stemmer.stem(text)\n",
    "    return output\n",
    "\n",
    "\n",
    "def stemming_sentence(text):\n",
    "    output = \"\"\n",
    "    for token in tokenisasi(text):\n",
    "        output = output + stemming(token) + \" \"\n",
    "    return output[:-1]\n",
    "\n",
    "doc_dict_raw = {}\n",
    "doc_dict_raw['doc1'] = \"pengembangan sistem informasi penjadwalan\"\n",
    "doc_dict_raw['doc2'] = \"pengembangan model analisis sentimen berita\"\n",
    "doc_dict_raw['doc3'] = \"analisis sistem input output\"\n",
    "doc_dict_raw['doc4'] = \"pengembangan sistem informasi akademik universitas\"\n",
    "doc_dict_raw['doc5'] = \"pengembangan sistem cari berita ekonomi\"\n",
    "doc_dict_raw['doc6'] = \"analisis sistem neraca nasional\"\n",
    "doc_dict_raw['doc7'] = \"pengembangan sistem informasi layanan statistik\"\n",
    "doc_dict_raw['doc8'] = \"pengembangan sistem pencarian skripsi di universitas\"\n",
    "doc_dict_raw['doc9'] = \"analisis sentimen publik terhadap pemerintah\"\n",
    "doc_dict_raw['doc10'] = \"pengembangan model klasifikasi sentimen berita\"\n",
    "\n",
    "doc_dict = {}\n",
    "for doc_id, doc in doc_dict_raw.items():\n",
    "    doc_dict[doc_id] = stemming_sentence(doc)\n",
    "print(doc_dict)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f2bc3c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kembang\n",
      "sistem\n",
      "informasi\n",
      "jadwal\n",
      "kembang\n",
      "model\n",
      "analisis\n",
      "sentimen\n",
      "berita\n",
      "analisis\n",
      "sistem\n",
      "input\n",
      "output\n",
      "kembang\n",
      "sistem\n",
      "informasi\n",
      "akademik\n",
      "universitas\n",
      "kembang\n",
      "sistem\n",
      "cari\n",
      "berita\n",
      "ekonomi\n",
      "analisis\n",
      "sistem\n",
      "neraca\n",
      "nasional\n",
      "kembang\n",
      "sistem\n",
      "informasi\n",
      "layan\n",
      "statistik\n",
      "kembang\n",
      "sistem\n",
      "cari\n",
      "skripsi\n",
      "di\n",
      "universitas\n",
      "analisis\n",
      "sentimen\n",
      "publik\n",
      "hadap\n",
      "perintah\n",
      "kembang\n",
      "model\n",
      "klasifikasi\n",
      "sentimen\n",
      "berita\n",
      "['kembang', 'sistem', 'informasi', 'jadwal', 'model', 'analisis', 'sentimen', 'berita', 'input', 'output', 'akademik', 'universitas', 'cari', 'ekonomi', 'neraca', 'nasional', 'layan', 'statistik', 'skripsi', 'di', 'publik', 'hadap', 'perintah', 'klasifikasi']\n",
      "{'kembang': ['doc1', 'doc2', 'doc4', 'doc5', 'doc7', 'doc8', 'doc10'], 'sistem': ['doc1', 'doc3', 'doc4', 'doc5', 'doc6', 'doc7', 'doc8'], 'informasi': ['doc1', 'doc4', 'doc7'], 'jadwal': ['doc1'], 'model': ['doc2', 'doc10'], 'analisis': ['doc2', 'doc3', 'doc6', 'doc9'], 'sentimen': ['doc2', 'doc9', 'doc10'], 'berita': ['doc2', 'doc5', 'doc10'], 'input': ['doc3'], 'output': ['doc3'], 'akademik': ['doc4'], 'universitas': ['doc4', 'doc8'], 'cari': ['doc5', 'doc8'], 'ekonomi': ['doc5'], 'neraca': ['doc6'], 'nasional': ['doc6'], 'layan': ['doc7'], 'statistik': ['doc7'], 'skripsi': ['doc8'], 'di': ['doc8'], 'publik': ['doc9'], 'hadap': ['doc9'], 'perintah': ['doc9'], 'klasifikasi': ['doc10']}\n"
     ]
    }
   ],
   "source": [
    "vocab = []\n",
    "\n",
    "inverted_index = {}\n",
    "\n",
    "for doc_id, doc in doc_dict.items():\n",
    "    for token in tokenisasi(doc):\n",
    "        print(token)\n",
    "        if token not in vocab:\n",
    "            vocab.append(token)\n",
    "            inverted_index[token] = []\n",
    "        if token in inverted_index:\n",
    "            if doc_id not in inverted_index[token]:\n",
    "                inverted_index[token].append(doc_id)\n",
    "print(vocab)\n",
    "print(inverted_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26b03c0",
   "metadata": {},
   "source": [
    "# EXACT TOP K Document Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ac8ebb5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kembang': 0, 'sistem': 1, 'informasi': 1, 'jadwal': 0, 'model': 0, 'analisis': 0, 'sentimen': 0, 'berita': 0, 'input': 0, 'output': 0, 'akademik': 0, 'universitas': 0, 'cari': 0, 'ekonomi': 0, 'neraca': 0, 'nasional': 0, 'layan': 0, 'statistik': 1, 'skripsi': 0, 'di': 0, 'publik': 0, 'hadap': 0, 'perintah': 0, 'klasifikasi': 0}\n"
     ]
    }
   ],
   "source": [
    "#Untuk penghitungan apakah terdapat kata di query yang terdapat di inverted index\n",
    "\n",
    "query = \"sistem informasi statistik\"\n",
    "def termFrequency(vocab, query):\n",
    "    tf_query = {}\n",
    "    for word in vocab:\n",
    "        tf_query[word] = query.count(word)\n",
    "    return tf_query\n",
    "\n",
    "tf_query = termFrequency(vocab,query)\n",
    "\n",
    "print(tf_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "df3810b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'doc1': {'kembang': 1.1383026981662814, 'sistem': 1.1383026981662814, 'informasi': 1.4393326938302626, 'jadwal': 1.7403626894942439, 'model': 0.0, 'analisis': 0.0, 'sentimen': 0.0, 'berita': 0.0, 'input': 0.0, 'output': 0.0, 'akademik': 0.0, 'universitas': 0.0, 'cari': 0.0, 'ekonomi': 0.0, 'neraca': 0.0, 'nasional': 0.0, 'layan': 0.0, 'statistik': 0.0, 'skripsi': 0.0, 'di': 0.0, 'publik': 0.0, 'hadap': 0.0, 'perintah': 0.0, 'klasifikasi': 0.0}, 'doc2': {'kembang': 1.1383026981662814, 'sistem': 0.0, 'informasi': 0.0, 'jadwal': 0.0, 'model': 1.5642714304385625, 'analisis': 1.3424226808222062, 'sentimen': 1.4393326938302626, 'berita': 1.4393326938302626, 'input': 0.0, 'output': 0.0, 'akademik': 0.0, 'universitas': 0.0, 'cari': 0.0, 'ekonomi': 0.0, 'neraca': 0.0, 'nasional': 0.0, 'layan': 0.0, 'statistik': 0.0, 'skripsi': 0.0, 'di': 0.0, 'publik': 0.0, 'hadap': 0.0, 'perintah': 0.0, 'klasifikasi': 0.0}, 'doc3': {'kembang': 0.0, 'sistem': 1.1383026981662814, 'informasi': 0.0, 'jadwal': 0.0, 'model': 0.0, 'analisis': 1.3424226808222062, 'sentimen': 0.0, 'berita': 0.0, 'input': 1.7403626894942439, 'output': 1.7403626894942439, 'akademik': 0.0, 'universitas': 0.0, 'cari': 0.0, 'ekonomi': 0.0, 'neraca': 0.0, 'nasional': 0.0, 'layan': 0.0, 'statistik': 0.0, 'skripsi': 0.0, 'di': 0.0, 'publik': 0.0, 'hadap': 0.0, 'perintah': 0.0, 'klasifikasi': 0.0}, 'doc4': {'kembang': 1.1383026981662814, 'sistem': 1.1383026981662814, 'informasi': 1.4393326938302626, 'jadwal': 0.0, 'model': 0.0, 'analisis': 0.0, 'sentimen': 0.0, 'berita': 0.0, 'input': 0.0, 'output': 0.0, 'akademik': 1.7403626894942439, 'universitas': 1.5642714304385625, 'cari': 0.0, 'ekonomi': 0.0, 'neraca': 0.0, 'nasional': 0.0, 'layan': 0.0, 'statistik': 0.0, 'skripsi': 0.0, 'di': 0.0, 'publik': 0.0, 'hadap': 0.0, 'perintah': 0.0, 'klasifikasi': 0.0}, 'doc5': {'kembang': 1.1383026981662814, 'sistem': 1.1383026981662814, 'informasi': 0.0, 'jadwal': 0.0, 'model': 0.0, 'analisis': 0.0, 'sentimen': 0.0, 'berita': 1.4393326938302626, 'input': 0.0, 'output': 0.0, 'akademik': 0.0, 'universitas': 0.0, 'cari': 1.5642714304385625, 'ekonomi': 1.7403626894942439, 'neraca': 0.0, 'nasional': 0.0, 'layan': 0.0, 'statistik': 0.0, 'skripsi': 0.0, 'di': 0.0, 'publik': 0.0, 'hadap': 0.0, 'perintah': 0.0, 'klasifikasi': 0.0}, 'doc6': {'kembang': 0.0, 'sistem': 1.1383026981662814, 'informasi': 0.0, 'jadwal': 0.0, 'model': 0.0, 'analisis': 1.3424226808222062, 'sentimen': 0.0, 'berita': 0.0, 'input': 0.0, 'output': 0.0, 'akademik': 0.0, 'universitas': 0.0, 'cari': 0.0, 'ekonomi': 0.0, 'neraca': 1.7403626894942439, 'nasional': 1.7403626894942439, 'layan': 0.0, 'statistik': 0.0, 'skripsi': 0.0, 'di': 0.0, 'publik': 0.0, 'hadap': 0.0, 'perintah': 0.0, 'klasifikasi': 0.0}, 'doc7': {'kembang': 1.1383026981662814, 'sistem': 1.1383026981662814, 'informasi': 1.4393326938302626, 'jadwal': 0.0, 'model': 0.0, 'analisis': 0.0, 'sentimen': 0.0, 'berita': 0.0, 'input': 0.0, 'output': 0.0, 'akademik': 0.0, 'universitas': 0.0, 'cari': 0.0, 'ekonomi': 0.0, 'neraca': 0.0, 'nasional': 0.0, 'layan': 1.7403626894942439, 'statistik': 1.7403626894942439, 'skripsi': 0.0, 'di': 0.0, 'publik': 0.0, 'hadap': 0.0, 'perintah': 0.0, 'klasifikasi': 0.0}, 'doc8': {'kembang': 1.1383026981662814, 'sistem': 1.1383026981662814, 'informasi': 0.0, 'jadwal': 0.0, 'model': 0.0, 'analisis': 0.0, 'sentimen': 0.0, 'berita': 0.0, 'input': 0.0, 'output': 0.0, 'akademik': 0.0, 'universitas': 1.5642714304385625, 'cari': 1.5642714304385625, 'ekonomi': 0.0, 'neraca': 0.0, 'nasional': 0.0, 'layan': 0.0, 'statistik': 0.0, 'skripsi': 1.7403626894942439, 'di': 1.7403626894942439, 'publik': 0.0, 'hadap': 0.0, 'perintah': 0.0, 'klasifikasi': 0.0}, 'doc9': {'kembang': 0.0, 'sistem': 0.0, 'informasi': 0.0, 'jadwal': 0.0, 'model': 0.0, 'analisis': 1.3424226808222062, 'sentimen': 1.4393326938302626, 'berita': 0.0, 'input': 0.0, 'output': 0.0, 'akademik': 0.0, 'universitas': 0.0, 'cari': 0.0, 'ekonomi': 0.0, 'neraca': 0.0, 'nasional': 0.0, 'layan': 0.0, 'statistik': 0.0, 'skripsi': 0.0, 'di': 0.0, 'publik': 1.7403626894942439, 'hadap': 1.7403626894942439, 'perintah': 1.7403626894942439, 'klasifikasi': 0.0}, 'doc10': {'kembang': 1.1383026981662814, 'sistem': 0.0, 'informasi': 0.0, 'jadwal': 0.0, 'model': 1.5642714304385625, 'analisis': 0.0, 'sentimen': 1.4393326938302626, 'berita': 1.4393326938302626, 'input': 0.0, 'output': 0.0, 'akademik': 0.0, 'universitas': 0.0, 'cari': 0.0, 'ekonomi': 0.0, 'neraca': 0.0, 'nasional': 0.0, 'layan': 0.0, 'statistik': 0.0, 'skripsi': 0.0, 'di': 0.0, 'publik': 0.0, 'hadap': 0.0, 'perintah': 0.0, 'klasifikasi': 1.7403626894942439}}\n"
     ]
    }
   ],
   "source": [
    "def wordDocFre(vocab, doc_dict):\n",
    "    df = {}\n",
    "    for word in vocab:\n",
    "        frq = 0\n",
    "        for doc in doc_dict.values():\n",
    "            if word in tokenisasi(doc):\n",
    "                frq = frq + 1\n",
    "        df[word] = frq\n",
    "    return df\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def inverseDocFre(vocab, doc_fre,length):\n",
    "    idf = {}\n",
    "    for word in vocab:\n",
    "        idf[word] = idf[word] = 1+ np.log10((length + 1)/(doc_fre[word]+1))\n",
    "    return idf\n",
    "\n",
    "def termFrequencyInDoc(vocab, doc_dict):\n",
    "    tf_docs = {}\n",
    "    for doc_id in doc_dict.keys():\n",
    "        tf_docs[doc_id] = {}\n",
    "    for word in vocab:\n",
    "        for doc_id,doc in doc_dict.items():\n",
    "            tf_docs[doc_id][word] = doc.count(word)\n",
    "    return tf_docs\n",
    "\n",
    "def tfidf(vocab, tf, idf_scr, doc_dict):\n",
    "    tf_idf_scr = {}\n",
    "    for doc_id in doc_dict.keys():\n",
    "        tf_idf_scr[doc_id] = {}\n",
    "    for word in vocab:\n",
    "        for doc_id,doc in doc_dict.items():\n",
    "            tf_idf_scr[doc_id][word] = tf[doc_id][word] * idf_scr[word]\n",
    "    return tf_idf_scr\n",
    "\n",
    "\n",
    "tf_idf = tfidf(vocab, termFrequencyInDoc(vocab, doc_dict), inverseDocFre(vocab, wordDocFre(vocab, doc_dict),len(doc_dict)), doc_dict)\n",
    "print(tf_idf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "baf8f2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.1383027  1.1383027  0.         1.1383027  1.1383027  0.\n",
      "  1.1383027  1.1383027  0.         1.1383027 ]\n",
      " [1.1383027  0.         1.1383027  1.1383027  1.1383027  1.1383027\n",
      "  1.1383027  1.1383027  0.         0.        ]\n",
      " [1.43933269 0.         0.         1.43933269 0.         0.\n",
      "  1.43933269 0.         0.         0.        ]\n",
      " [1.74036269 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         1.56427143 0.         0.         0.         0.\n",
      "  0.         0.         0.         1.56427143]\n",
      " [0.         1.34242268 1.34242268 0.         0.         1.34242268\n",
      "  0.         0.         1.34242268 0.        ]\n",
      " [0.         1.43933269 0.         0.         0.         0.\n",
      "  0.         0.         1.43933269 1.43933269]\n",
      " [0.         1.43933269 0.         0.         1.43933269 0.\n",
      "  0.         0.         0.         1.43933269]\n",
      " [0.         0.         1.74036269 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         1.74036269 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         1.74036269 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         1.56427143 0.         0.\n",
      "  0.         1.56427143 0.         0.        ]\n",
      " [0.         0.         0.         0.         1.56427143 0.\n",
      "  0.         1.56427143 0.         0.        ]\n",
      " [0.         0.         0.         0.         1.74036269 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         1.74036269\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         1.74036269\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  1.74036269 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  1.74036269 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         1.74036269 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         1.74036269 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         1.74036269 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         1.74036269 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         1.74036269 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         1.74036269]]\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Term - Document, Matrix\n",
    "\n",
    "TD = np.zeros((len(vocab),len(doc_dict)))\n",
    "for word in vocab:\n",
    "    for doc_id, doc in tf_idf.items():\n",
    "        ind1 = vocab.index(word)\n",
    "        ind2 = list(tf_idf.keys()).index(doc_id)\n",
    "        TD[ind1][ind2] = tf_idf[doc_id][word]\n",
    "print(TD)\n",
    "print(len(TD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e913eba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.        ]\n",
      " [1.1383027 ]\n",
      " [1.43933269]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [1.74036269]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]]\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "#Term - Query Matrix\n",
    "import numpy as np\n",
    "\n",
    "idf = inverseDocFre(vocab, wordDocFre(vocab, doc_dict),len(doc_dict))\n",
    "\n",
    "\n",
    "TQ = np.zeros((len(vocab),1)) #hanya 1 query\n",
    "for word in vocab:\n",
    "    ind1 = vocab.index(word)\n",
    "    TQ[ind1][0] = tf_query[word]*idf[word]\n",
    "print(TQ)\n",
    "print(len(TQ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1473af20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#COSINE SIMILARITY\n",
    "\n",
    "import math\n",
    "def cosine_sim(vec1, vec2):\n",
    "    vec1 = list(vec1)\n",
    "    vec2 = list(vec2)\n",
    "    dot_prod = 0\n",
    "    for i, v in enumerate (vec1):\n",
    "        dot_prod += v * vec2[i]\n",
    "    mag_1 = math.sqrt(sum([x**2 for x in vec1]))\n",
    "    mag_2 = math.sqrt(sum([x**2 for x in vec2]))\n",
    "    \n",
    "    return dot_prod / (mag_1*mag_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ae3a641e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.480079152100338\n",
      "0.0\n",
      "0.16932053623985205\n"
     ]
    }
   ],
   "source": [
    "print(cosine_sim(TQ[:, 0], TD[:, 0])) #query & doc1\n",
    "print(cosine_sim(TQ[:, 0], TD[:, 1])) #query & doc2\n",
    "print(cosine_sim(TQ[:, 0], TD[:, 2])) #query & doc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "98cc7a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "def exact_top_k(doc_dict, TD, q, k):\n",
    "    relevance_scores = {}\n",
    "    i = 0\n",
    "    for doc_id in doc_dict.keys():\n",
    "        relevance_scores[doc_id] = cosine_sim(q, TD[:, i])\n",
    "        i = i+1\n",
    "    sorted_value = OrderedDict(sorted(relevance_scores.items(), key = lambda x: x[1], reverse = True))\n",
    "    top_k = {j: sorted_value[j] for j in list(sorted_value)[:k]}\n",
    "    return top_k\n",
    "\n",
    "top_2 = exact_top_k(doc_dict, TD, TQ[:, 0], 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5ef90ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc7': 0.7724111379389828,\n",
       " 'doc1': 0.480079152100338,\n",
       " 'doc4': 0.41815389455319024}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_3 = exact_top_k(doc_dict, TD, TQ[:, 0], 3)\n",
    "top_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f3fdb7",
   "metadata": {},
   "source": [
    "### Inexact Top K Document Retrieval (Scoring)\n",
    "#### ELIMINASI QUERY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8f77d3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_elim_simple(query, doc_dict):\n",
    "    remove_list =[]\n",
    "    for doc_id,doc in doc_dict.items():\n",
    "        n = 0\n",
    "        for word in tokenisasi(query):\n",
    "            if stemming(word) in doc:\n",
    "                n = n+1\n",
    "        if n==0:\n",
    "            remove_list.append(doc_id)\n",
    "    for key in remove_list:\n",
    "        del doc_dict[key]\n",
    "    return doc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "33c7ca40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'doc1': 'kembang sistem informasi jadwal', 'doc3': 'analisis sistem input output', 'doc4': 'kembang sistem informasi akademik universitas', 'doc5': 'kembang sistem cari berita ekonomi', 'doc6': 'analisis sistem neraca nasional', 'doc7': 'kembang sistem informasi layan statistik', 'doc8': 'kembang sistem cari skripsi di universitas'}\n"
     ]
    }
   ],
   "source": [
    "query = \"sistem informasi statistik\"\n",
    "doc_dicts = index_elim_simple(query, doc_dict)\n",
    "print(doc_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8b2447bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elim_query(query, idf_dict, idf_scores):\n",
    "    for term in tokenisasi(query):\n",
    "        if idf_dict[stemming(term)] < idf_scores:\n",
    "            query = query.replace(term+\" \", \"\")\n",
    "            query = query.replace(term, \"\")\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5bd82dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistik\n"
     ]
    }
   ],
   "source": [
    "query = \"sistem informasi statistik\"\n",
    "query = elim_query(query, idf, 1.5)\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376f90db",
   "metadata": {},
   "source": [
    "# Champion List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7a449b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_championlist(inverted_index, tf_idf, r):\n",
    "    champion_list = {}\n",
    "    for term in inverted_index.keys():\n",
    "        weight_scores = {}\n",
    "        for doc_id,tf in tf_idf.items():\n",
    "            if tf_idf[doc_id][term]!=0:\n",
    "                weight_scores[doc_id] = tf_idf[doc_id][term]\n",
    "                sorted_value = OrderedDict(sorted(weight_scores.items(), key=lambda x: x[1], reverse = True))\n",
    "                top_r = {j: sorted_value[j] for j in list(sorted_value)[:r]}\n",
    "                champion_list[term]=list(top_r.keys())\n",
    "    return champion_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c29b597f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kembang': ['doc1', 'doc2'],\n",
       " 'sistem': ['doc1', 'doc3'],\n",
       " 'informasi': ['doc1', 'doc4'],\n",
       " 'jadwal': ['doc1'],\n",
       " 'model': ['doc2', 'doc10'],\n",
       " 'analisis': ['doc2', 'doc3'],\n",
       " 'sentimen': ['doc2', 'doc9'],\n",
       " 'berita': ['doc2', 'doc5'],\n",
       " 'input': ['doc3'],\n",
       " 'output': ['doc3'],\n",
       " 'akademik': ['doc4'],\n",
       " 'universitas': ['doc4', 'doc8'],\n",
       " 'cari': ['doc5', 'doc8'],\n",
       " 'ekonomi': ['doc5'],\n",
       " 'neraca': ['doc6'],\n",
       " 'nasional': ['doc6'],\n",
       " 'layan': ['doc7'],\n",
       " 'statistik': ['doc7'],\n",
       " 'skripsi': ['doc8'],\n",
       " 'di': ['doc8'],\n",
       " 'publik': ['doc9'],\n",
       " 'hadap': ['doc9'],\n",
       " 'perintah': ['doc9'],\n",
       " 'klasifikasi': ['doc10']}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = 2\n",
    "create_championlist(inverted_index, tf_idf, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41567c4e",
   "metadata": {},
   "source": [
    "# PERT 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0f544bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\asus\\anaconda3\\envs\\ir_env\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\asus\\anaconda3\\envs\\ir_env\\lib\\site-packages (from scikit-learn) (1.9.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\asus\\anaconda3\\envs\\ir_env\\lib\\site-packages (from scikit-learn) (1.23.2)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\asus\\anaconda3\\envs\\ir_env\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\asus\\anaconda3\\envs\\ir_env\\lib\\site-packages (from scikit-learn) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fc6250ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b58e2e85",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'doc2' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [136]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m nrel_vecs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m nrel_vecs_id:\n\u001b[1;32m----> 9\u001b[0m     nrel_vecs\u001b[38;5;241m.\u001b[39mappend(DT[\u001b[43mdoc_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m,:])\n",
      "\u001b[1;31mValueError\u001b[0m: 'doc2' is not in list"
     ]
    }
   ],
   "source": [
    "rel_vecs_id = [\"doc1\", \"doc4\", \"doc5\", \"doc7\", \"doc8\"]\n",
    "nrel_vecs_id = [\"doc2\", \"doc3\", \"doc6\", \"doc9\", \"doc10\"]\n",
    "\n",
    "rel_vecs = []\n",
    "for doc in rel_vecs_id:\n",
    "    rel_vecs.append(DT[doc_ids.index(doc),:])\n",
    "nrel_vecs = []\n",
    "for doc in nrel_vecs_id:\n",
    "    nrel_vecs.append(DT[doc_ids.index(doc),:])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c424e297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.1383027  1.1383027  1.43933269 1.74036269 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [1.1383027  0.         0.         0.         1.56427143 1.34242268\n",
      "  1.43933269 1.43933269 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         1.1383027  0.         0.         0.         1.34242268\n",
      "  0.         0.         1.74036269 1.74036269 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [1.1383027  1.1383027  1.43933269 0.         0.         0.\n",
      "  0.         0.         0.         0.         1.74036269 1.56427143\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [1.1383027  1.1383027  0.         0.         0.         0.\n",
      "  0.         1.43933269 0.         0.         0.         0.\n",
      "  1.56427143 1.74036269 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         1.1383027  0.         0.         0.         1.34242268\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         1.74036269 1.74036269 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [1.1383027  1.1383027  1.43933269 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         1.74036269 1.74036269\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [1.1383027  1.1383027  0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         1.56427143\n",
      "  1.56427143 0.         0.         0.         0.         0.\n",
      "  1.74036269 1.74036269 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         1.34242268\n",
      "  1.43933269 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         1.74036269 1.74036269 1.74036269 0.        ]\n",
      " [1.1383027  0.         0.         0.         1.56427143 0.\n",
      "  1.43933269 1.43933269 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         1.74036269]]\n",
      "[[ 1.10277251 -0.84211635]]\n",
      "[[ 1.674812   -0.87041409]\n",
      " [ 1.90082714  2.03259184]\n",
      " [ 1.01677258  0.25034005]\n",
      " [ 2.07214749 -1.29201546]\n",
      " [ 2.08433982 -0.1838961 ]\n",
      " [ 1.01677258  0.25034005]\n",
      " [ 1.88736399 -1.08242562]\n",
      " [ 2.29505316 -1.37236284]\n",
      " [ 0.86908445  2.28621673]\n",
      " [ 1.79303872  1.86906526]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DT = TD.transpose()\n",
    "print (DT)\n",
    "model = TruncatedSVD(n_components=2, random_state=7).fit(DT)\n",
    "DT_reduced = model.transform(DT)\n",
    "QT_reduced = model.transform(TQ.transpose())\n",
    "print (QT_reduced)\n",
    "print (DT_reduced)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(QT_reduced[:, 0], QT_reduced[:, 1], color=[\"red\"])\n",
    "doc_ids=list(doc_dict.keys())\n",
    "for i, txt in enumerate (doc_ids):\n",
    "    plt.annotate(txt, (DT_reduced[i, 0], DT_reduced[i, 1]))\n",
    "    if txt in rel_vecs_id:\n",
    "        plt.scatter(DT_reduced[i, 0], DT_reduced[i, 1], marker='o', color=['purple'])\n",
    "    elif txt in nrel_vecs_id:\n",
    "        plt.scatter(DT_reduced[i, 0], DT_reduced[i, 1], marker='x', color=['blue'])\n",
    "plt.annotate(\"query\", (QT_reduced[0, 0], QT_reduced[0, 1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "041b27d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'doc8': array([0.77241114]), 'doc1': array([0.48007915]), 'doc5': array([0.41815389]), 'doc4': array([0.16932054]), 'doc7': array([0.16932054])}\n"
     ]
    }
   ],
   "source": [
    "top_5 = exact_top_k(doc_dict, TD, TQ[:,], 5)\n",
    "print(top_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8fce3ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.        ]\n",
      " [1.1383027 ]\n",
      " [1.43933269]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [1.74036269]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]]\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "query_vecs = TQ.transpose()\n",
    "alpha = 1\n",
    "beta = 0.75\n",
    "gamma = 0.15\n",
    "\n",
    "# Update query vector with Rocchio algorithm\n",
    "query_vecs = alpha * query_vecs + beta * np.mean(rel_vecs, axis=0) - gamma * np.mean(nrel_vecs, axis=0)\n",
    "query_vecs[query_vecs < 0] = 0\n",
    "\n",
    "print(TQ)\n",
    "print(query_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "2addeba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'doc1': nan, 'doc3': nan, 'doc4': nan, 'doc5': nan, 'doc6': nan}\n"
     ]
    }
   ],
   "source": [
    "top_5 = exact_top_k(doc_dict, TD, query_vecs[0, :].transpose(), 5)\n",
    "print(top_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "06f1af67",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nTruncatedSVD does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [140]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m QT1_reduced \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_vecs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(QT_reduced[:,\u001b[38;5;241m0\u001b[39m], QT_reduced[:,\u001b[38;5;241m1\u001b[39m], color\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ir_env\\lib\\site-packages\\sklearn\\decomposition\\_truncated_svd.py:287\u001b[0m, in \u001b[0;36mTruncatedSVD.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;124;03m\"\"\"Perform dimensionality reduction on X.\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;124;03m    Reduced version of X. This will always be a dense array.\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    286\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 287\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponents_\u001b[38;5;241m.\u001b[39mT)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ir_env\\lib\\site-packages\\sklearn\\base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 577\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    578\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ir_env\\lib\\site-packages\\sklearn\\utils\\validation.py:899\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    893\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    894\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    895\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    896\u001b[0m         )\n\u001b[0;32m    898\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 899\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    901\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    903\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    904\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    906\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    907\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ir_env\\lib\\site-packages\\sklearn\\utils\\validation.py:146\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    125\u001b[0m             \u001b[38;5;129;01mnot\u001b[39;00m allow_nan\n\u001b[0;32m    126\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m estimator_name\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    131\u001b[0m             \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    132\u001b[0m             msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    133\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    134\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    144\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    145\u001b[0m             )\n\u001b[1;32m--> 146\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n\u001b[0;32m    148\u001b[0m \u001b[38;5;66;03m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan:\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nTruncatedSVD does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "QT1_reduced = model.transform(query_vecs)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(QT_reduced[:,0], QT_reduced[:,1], color=[\"red\"])\n",
    "plt.scatter(QT1_reduced[:,0], QT1_reduced[:,1], color=[\"green\"])\n",
    "doc_ids=list(doc_dict.keys())\n",
    "for i, txt in enumerate (doc_ids):\n",
    "    plt.annotate(txt,(DT_reduced[i,0], DT_reduced[i,1]))\n",
    "    if txt in rel_vecs_id:\n",
    "        plt.scatter(DT_reduced[i,0], DT_reduced[i,1], marker='o', color=[\"purple\"])\n",
    "    elif txt in nrel_vecs_id:\n",
    "        plt.scatter(DT_reduced[i,0], DT_reduced[i,1], marker='x', color=[\"blue\"])\n",
    "#plt.legend()\n",
    "plt.annotate(\"query\",(QT_reduced[0,0], QT_reduced[0,1]))\n",
    "plt.annotate(\"new query\",(QT1_reduced[:,0], QT1_reduced[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c9447d5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [100]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[0;32m      2\u001b[0m nltk\u001b[38;5;241m.\u001b[39mdonwload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwordnet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m nltk\u001b[38;5;241m.\u001b[39mdonwload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124momw-1.4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.donwload('wordnet')\n",
    "nltk.donwload('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54316298",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
